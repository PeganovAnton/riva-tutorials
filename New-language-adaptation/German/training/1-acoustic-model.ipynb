{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Acoustic Model with subword tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HqBQwLAsme9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: wget in /opt/conda/lib/python3.8/site-packages (3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.2.4-1ubuntu0.1).\n",
      "libsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\n",
      "sox is already the newest version (14.4.2+git20190427-2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: unidecode in /opt/conda/lib/python3.8/site-packages (1.3.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting nemo_toolkit[all]\n",
      "  Cloning https://github.com/NVIDIA/NeMo.git (to revision main) to /tmp/pip-install-3hdq52c5/nemo-toolkit_041a7e8147f4492ea4407389b985771b\n",
      "  Running command git clone -q https://github.com/NVIDIA/NeMo.git /tmp/pip-install-3hdq52c5/nemo-toolkit_041a7e8147f4492ea4407389b985771b\n",
      "  Resolved https://github.com/NVIDIA/NeMo.git to commit 7a9a8f012729f481b6ef5d6aabddce4a891124eb\n",
      "Requirement already satisfied: setuptools==59.5.0 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (59.5.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.22.0)\n",
      "Requirement already satisfied: onnx>=1.7.0 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (2.8.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.11.0a0+bfe5ad2)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.13.3)\n",
      "Requirement already satisfied: ruamel.yaml in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.17.21)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.24.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (4.62.3)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.53.1)\n",
      "Requirement already satisfied: wget in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (3.2)\n",
      "Requirement already satisfied: frozendict in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (2.3.0)\n",
      "Requirement already satisfied: unidecode in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.3.3)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.4.0)\n",
      "Requirement already satisfied: black==19.10b0 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (19.10b0)\n",
      "Requirement already satisfied: isort[requirements]<5 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (4.3.21)\n",
      "Requirement already satisfied: parameterized in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.8.1)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (6.2.5)\n",
      "Requirement already satisfied: pytest-runner in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (6.0.0)\n",
      "Requirement already satisfied: sphinx in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (4.4.0)\n",
      "Requirement already satisfied: sphinxcontrib-bibtex in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (2.4.1)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.12.11)\n",
      "Requirement already satisfied: inflect in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (5.4.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (2022.1.18)\n",
      "Requirement already satisfied: pynini==2.1.4 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (2.1.4)\n",
      "Requirement already satisfied: pytorch-lightning>=1.6.1 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.6.3)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1rc0 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.7.2)\n",
      "Requirement already satisfied: transformers>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (4.17.0)\n",
      "Requirement already satisfied: webdataset<=0.1.62,>=0.1.48 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.1.62)\n",
      "Requirement already satisfied: omegaconf<2.2,>=2.1.2 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (2.1.2)\n",
      "Requirement already satisfied: hydra-core<1.2,>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.1.1)\n",
      "Requirement already satisfied: pyyaml<6 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (5.4.1)\n",
      "Requirement already satisfied: sentencepiece<1.0.0 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.1.96)\n",
      "Requirement already satisfied: youtokentome>=1.0.5 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.0.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.3.5)\n",
      "Requirement already satisfied: braceexpand in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.1.7)\n",
      "Requirement already satisfied: editdistance in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.6.0)\n",
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.8.1)\n",
      "Requirement already satisfied: marshmallow in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (3.14.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (21.3)\n",
      "Requirement already satisfied: soundfile in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.10.3.post1)\n",
      "Requirement already satisfied: sox in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.4.1)\n",
      "Requirement already satisfied: kaldi-python-io in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.2.2)\n",
      "Requirement already satisfied: kaldiio in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (2.17.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.6.3)\n",
      "Requirement already satisfied: g2p_en in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (2.1.0)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.25.1)\n",
      "Requirement already satisfied: pyannote.core in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (4.3)\n",
      "Requirement already satisfied: pyannote.metrics in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (3.2)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (7.6.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (3.5.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (8.2.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.12.0a0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.21.15)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (3.6.0)\n",
      "Requirement already satisfied: rapidfuzz in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (2.0.6)\n",
      "Requirement already satisfied: gdown in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (4.4.0)\n",
      "Requirement already satisfied: sacrebleu[ja] in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (2.0.0)\n",
      "Requirement already satisfied: sacremoses>=0.0.43 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.0.47)\n",
      "Requirement already satisfied: nltk>=3.6.5 in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (3.6.7)\n",
      "Requirement already satisfied: fasttext in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.9.2)\n",
      "Requirement already satisfied: opencc in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (1.1.3)\n",
      "Requirement already satisfied: pangu in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (4.0.6.1)\n",
      "Requirement already satisfied: jieba in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.42.1)\n",
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (6.1.1)\n",
      "Requirement already satisfied: flask_restful in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.3.9)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.4.1)\n",
      "Requirement already satisfied: ijson in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (3.1.4)\n",
      "Requirement already satisfied: pypinyin in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.46.0)\n",
      "Requirement already satisfied: attrdict in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (2.0.1)\n",
      "Requirement already satisfied: pystoi in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.3.3)\n",
      "Requirement already satisfied: pesq in /opt/conda/lib/python3.8/site-packages (from nemo_toolkit[all]) (0.0.3)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /opt/conda/lib/python3.8/site-packages (from black==19.10b0->nemo_toolkit[all]) (21.4.0)\n",
      "Requirement already satisfied: click>=6.5 in /opt/conda/lib/python3.8/site-packages (from black==19.10b0->nemo_toolkit[all]) (8.0.3)\n",
      "Requirement already satisfied: pathspec<1,>=0.6 in /opt/conda/lib/python3.8/site-packages (from black==19.10b0->nemo_toolkit[all]) (0.9.0)\n",
      "Requirement already satisfied: typed-ast>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from black==19.10b0->nemo_toolkit[all]) (1.5.2)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.8/site-packages (from black==19.10b0->nemo_toolkit[all]) (1.4.4)\n",
      "Requirement already satisfied: toml>=0.9.4 in /opt/conda/lib/python3.8/site-packages (from black==19.10b0->nemo_toolkit[all]) (0.10.2)\n",
      "Requirement already satisfied: Cython>=0.29 in /opt/conda/lib/python3.8/site-packages (from pynini==2.1.4->nemo_toolkit[all]) (0.29.26)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /opt/conda/lib/python3.8/site-packages (from hydra-core<1.2,>=1.1.0->nemo_toolkit[all]) (4.8)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.8/site-packages (from hydra-core<1.2,>=1.1.0->nemo_toolkit[all]) (5.4.0)\n",
      "Requirement already satisfied: pip-api in /opt/conda/lib/python3.8/site-packages (from isort[requirements]<5->nemo_toolkit[all]) (0.0.28)\n",
      "Requirement already satisfied: pipreqs in /opt/conda/lib/python3.8/site-packages (from isort[requirements]<5->nemo_toolkit[all]) (0.4.11)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->nemo_toolkit[all]) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->nemo_toolkit[all]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->nemo_toolkit[all]) (4.29.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->nemo_toolkit[all]) (3.0.6)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk>=3.6.5->nemo_toolkit[all]) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /opt/conda/lib/python3.8/site-packages (from onnx>=1.7.0->nemo_toolkit[all]) (3.19.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from onnx>=1.7.0->nemo_toolkit[all]) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.8/site-packages (from onnx>=1.7.0->nemo_toolkit[all]) (4.0.1)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning>=1.6.1->nemo_toolkit[all]) (2.8.0)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning>=1.6.1->nemo_toolkit[all]) (2022.1.0)\n",
      "Requirement already satisfied: pyDeprecate<0.4.0,>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning>=1.6.1->nemo_toolkit[all]) (0.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (3.8.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (1.43.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (2.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (3.3.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (1.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (4.10.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (3.1.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.0.1->nemo_toolkit[all]) (0.11.6)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers>=4.0.1->nemo_toolkit[all]) (3.4.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (6.0.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3->nemo_toolkit[all]) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from boto3->nemo_toolkit[all]) (0.5.2)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.15 in /opt/conda/lib/python3.8/site-packages (from boto3->nemo_toolkit[all]) (1.24.15)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.8/site-packages (from fasttext->nemo_toolkit[all]) (2.9.0)\n",
      "Requirement already satisfied: aniso8601>=0.82 in /opt/conda/lib/python3.8/site-packages (from flask_restful->nemo_toolkit[all]) (9.0.1)\n",
      "Requirement already satisfied: Flask>=0.8 in /opt/conda/lib/python3.8/site-packages (from flask_restful->nemo_toolkit[all]) (2.0.2)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.8/site-packages (from flask_restful->nemo_toolkit[all]) (2021.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.8/site-packages (from Flask>=0.8->flask_restful->nemo_toolkit[all]) (3.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.8/site-packages (from Flask>=0.8->flask_restful->nemo_toolkit[all]) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from Jinja2>=3.0->Flask>=0.8->flask_restful->nemo_toolkit[all]) (2.0.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.8/site-packages (from ftfy->nemo_toolkit[all]) (0.2.5)\n",
      "Requirement already satisfied: distance>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from g2p_en->nemo_toolkit[all]) (0.1.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.8/site-packages (from gdown->nemo_toolkit[all]) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4->gdown->nemo_toolkit[all]) (2.3.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->nemo_toolkit[all]) (7.31.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->nemo_toolkit[all]) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->nemo_toolkit[all]) (3.5.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->nemo_toolkit[all]) (1.0.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->nemo_toolkit[all]) (5.1.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->nemo_toolkit[all]) (6.7.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->nemo_toolkit[all]) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (0.1.3)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (7.1.2)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (1.5.4)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (1.5.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (4.8.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (2.11.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (3.0.24)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.18.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (5.1.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (4.9.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (0.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->nemo_toolkit[all]) (4.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->nemo_toolkit[all]) (0.18.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.7.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (6.4.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.12.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.13.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (6.4.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (21.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (2.21)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from librosa->nemo_toolkit[all]) (0.2.2)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa->nemo_toolkit[all]) (2.1.9)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.8/site-packages (from librosa->nemo_toolkit[all]) (1.6.0)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.8/site-packages (from numba->nemo_toolkit[all]) (0.36.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->nemo_toolkit[all]) (3.0.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (1.5.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.5.10)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.5.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.5.1)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.8/site-packages (from pip-api->isort[requirements]<5->nemo_toolkit[all]) (21.2.4)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.8/site-packages (from pipreqs->isort[requirements]<5->nemo_toolkit[all]) (0.6.2)\n",
      "Requirement already satisfied: yarg in /opt/conda/lib/python3.8/site-packages (from pipreqs->isort[requirements]<5->nemo_toolkit[all]) (0.1.9)\n",
      "Requirement already satisfied: simplejson>=3.8.1 in /opt/conda/lib/python3.8/site-packages (from pyannote.core->nemo_toolkit[all]) (3.17.6)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /opt/conda/lib/python3.8/site-packages (from pyannote.core->nemo_toolkit[all]) (2.4.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.8/site-packages (from pyannote.metrics->nemo_toolkit[all]) (0.8.9)\n",
      "Requirement already satisfied: sympy>=1.1 in /opt/conda/lib/python3.8/site-packages (from pyannote.metrics->nemo_toolkit[all]) (1.10)\n",
      "Requirement already satisfied: pyannote.database>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from pyannote.metrics->nemo_toolkit[all]) (4.1.3)\n",
      "Requirement already satisfied: typer[all]>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[all]) (0.4.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy>=1.1->pyannote.metrics->nemo_toolkit[all]) (1.2.1)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /opt/conda/lib/python3.8/site-packages (from typer[all]>=0.2.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[all]) (0.4.4)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from typer[all]>=0.2.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[all]) (1.4.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.8/site-packages (from pytest->nemo_toolkit[all]) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.8/site-packages (from pytest->nemo_toolkit[all]) (1.11.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.8/site-packages (from pytest->nemo_toolkit[all]) (1.1.1)\n",
      "Requirement already satisfied: jarowinkler<1.1.0,>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from rapidfuzz->nemo_toolkit[all]) (1.0.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.6.1->nemo_toolkit[all]) (1.7.1)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /opt/conda/lib/python3.8/site-packages (from ruamel.yaml->nemo_toolkit[all]) (0.2.6)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.8/site-packages (from sacrebleu[ja]->nemo_toolkit[all]) (2.4.0)\n",
      "Requirement already satisfied: ipadic<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from sacrebleu[ja]->nemo_toolkit[all]) (1.0.0)\n",
      "Requirement already satisfied: mecab-python3==1.0.3 in /opt/conda/lib/python3.8/site-packages (from sacrebleu[ja]->nemo_toolkit[all]) (1.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /opt/conda/lib/python3.8/site-packages (from sphinx->nemo_toolkit[all]) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from sphinx->nemo_toolkit[all]) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /opt/conda/lib/python3.8/site-packages (from sphinx->nemo_toolkit[all]) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /opt/conda/lib/python3.8/site-packages (from sphinx->nemo_toolkit[all]) (1.0.1)\n",
      "Requirement already satisfied: babel>=1.3 in /opt/conda/lib/python3.8/site-packages (from sphinx->nemo_toolkit[all]) (2.9.1)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /opt/conda/lib/python3.8/site-packages (from sphinx->nemo_toolkit[all]) (1.1.5)\n",
      "Requirement already satisfied: docutils<0.18,>=0.14 in /opt/conda/lib/python3.8/site-packages (from sphinx->nemo_toolkit[all]) (0.17.1)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /opt/conda/lib/python3.8/site-packages (from sphinx->nemo_toolkit[all]) (2.2.0)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /opt/conda/lib/python3.8/site-packages (from sphinx->nemo_toolkit[all]) (1.0.3)\n",
      "Requirement already satisfied: imagesize in /opt/conda/lib/python3.8/site-packages (from sphinx->nemo_toolkit[all]) (1.3.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /opt/conda/lib/python3.8/site-packages (from sphinx->nemo_toolkit[all]) (0.7.12)\n",
      "Requirement already satisfied: pybtex-docutils>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from sphinxcontrib-bibtex->nemo_toolkit[all]) (1.0.1)\n",
      "Requirement already satisfied: pybtex>=0.20 in /opt/conda/lib/python3.8/site-packages (from sphinxcontrib-bibtex->nemo_toolkit[all]) (0.24.0)\n",
      "Requirement already satisfied: latexcodec>=1.0.4 in /opt/conda/lib/python3.8/site-packages (from pybtex>=0.20->sphinxcontrib-bibtex->nemo_toolkit[all]) (2.0.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb->nemo_toolkit[all]) (1.5.7)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.8/site-packages (from wandb->nemo_toolkit[all]) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.8/site-packages (from wandb->nemo_toolkit[all]) (1.2.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb->nemo_toolkit[all]) (3.1.27)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb->nemo_toolkit[all]) (5.9.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from wandb->nemo_toolkit[all]) (0.4.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.8/site-packages (from wandb->nemo_toolkit[all]) (2.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from wandb->nemo_toolkit[all]) (1.0.8)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb->nemo_toolkit[all]) (2.1.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb->nemo_toolkit[all]) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->nemo_toolkit[all]) (5.0.0)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from yaspin>=1.0.0->wandb->nemo_toolkit[all]) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "mkdir: cannot create directory ‘configs’: File exists\n",
      "--2022-05-31 14:19:07--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/asr/conf/citrinet/config_bpe.yaml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4297 (4.2K) [text/plain]\n",
      "Saving to: ‘configs/config_bpe.yaml’\n",
      "\n",
      "config_bpe.yaml     100%[===================>]   4.20K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-05-31 14:19:08 (33.4 MB/s) - ‘configs/config_bpe.yaml’ saved [4297/4297]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nRemember to restart the runtime for the kernel to pick up any upgraded packages (e.g. matplotlib)!\\nAlternatively, you can uncomment the exit() below to crash and restart the kernel, in the case\\nthat you want to use the \"Run All Cells\" (or similar) option.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install wget\n",
    "!apt-get install sox libsndfile1 ffmpeg\n",
    "!pip install unidecode\n",
    "!pip install matplotlib>=3.3.2\n",
    "\n",
    "## Install NeMo\n",
    "BRANCH = 'main'\n",
    "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\n",
    "\n",
    "## Grab the config we'll use in this example\n",
    "!mkdir configs\n",
    "!wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/asr/conf/citrinet/config_bpe.yaml\n",
    "\n",
    "\"\"\"\n",
    "Remember to restart the runtime for the kernel to pick up any upgraded packages (e.g. matplotlib)!\n",
    "Alternatively, you can uncomment the exit() below to crash and restart the kernel, in the case\n",
    "that you want to use the \"Run All Cells\" (or similar) option.\n",
    "\"\"\"\n",
    "# exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPuyTHGTm8Q-"
   },
   "source": [
    "Let's begin constructing an ASR model that will use the subword tokenizer for its dataset pre-processing and post-processing steps.\n",
    "\n",
    "We will use a Citrinet model to demonstrate the usage of subword tokenization models for training and inference. Citrinet is a [QuartzNet-like architecture](https://arxiv.org/abs/1910.10261), but it uses subword-tokenization along with 8x subsampling and [Squeeze-and-Excitation](https://arxiv.org/abs/1709.01507) to achieve strong accuracy in transcriptions while still using non-autoregressive decoding for efficient inference.\n",
    "\n",
    "We'll be using the **Neural Modules (NeMo) toolkit** for this part, so if you haven't already, you should download and install NeMo and its dependencies. To do so, just follow the directions on the [GitHub page](https://github.com/NVIDIA/NeMo), or in the [documentation](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/).\n",
    "\n",
    "NeMo let us easily hook together the components (modules) of our model, such as the data layer, intermediate layers, and various losses, without worrying too much about implementation details of individual parts or connections between modules. NeMo also comes with complete models which only require your data and hyperparameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jALgpGLjmaCw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0rc0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NeMo's \"core\" package\n",
    "import nemo\n",
    "print(nemo.__version__)\n",
    "# NeMo's ASR collection - this collections contains complete ASR models and\n",
    "# building blocks (modules) for ASR\n",
    "import nemo.collections.asr as nemo_asr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDTC4fXZ5QnT"
   },
   "source": [
    "## Cross-Language Transfer Learning\n",
    "\n",
    "Transfer learning is an important machine learning technique that uses a model’s knowledge of one task to perform better on another. Fine-tuning is one of the techniques to perform transfer learning. It is an essential part of the recipe for many state-of-the-art results where a base model is first pretrained on a task with abundant training data and then fine-tuned on different tasks of interest where the training data is less abundant or even scarce.\n",
    "\n",
    "In ASR you might want to do fine-tuning in multiple scenarios, for example, when you want to improve your model's performance on a particular domain (medical, financial, etc.) or accented speech. You can even transfer learn from one language to another! Check out [this paper](https://arxiv.org/abs/2005.04290) for examples.\n",
    "\n",
    "Transfer learning with NeMo is simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN0LbDbY5YR1"
   },
   "source": [
    "-----\n",
    "First, let's create another tokenizer - perhaps using a larger vocabulary size than the small tokenizer we created earlier. Also we swap out `sentencepiece` for `BERT Word Piece` tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-05-31 14:19:12 cloud:56] Found existing object /root/.cache/torch/NeMo/NeMo_1.10.0rc0/stt_en_conformer_ctc_large/010120d9959425c7862c9843960b3235/stt_en_conformer_ctc_large.nemo.\n",
      "[NeMo I 2022-05-31 14:19:12 cloud:62] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.10.0rc0/stt_en_conformer_ctc_large/010120d9959425c7862c9843960b3235/stt_en_conformer_ctc_large.nemo\n",
      "[NeMo I 2022-05-31 14:19:12 common:789] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-05-31 14:19:15 mixins:166] Tokenizer SentencePieceTokenizer initialized with 128 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-05-31 14:19:15 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/NeMo_ASR_SET/English/v2.0/train/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 2048\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data/NeMo_ASR_SET/English/v2.0/train/audio__OP_0..4095_CL_.tar\n",
      "    \n",
      "[NeMo W 2022-05-31 14:19:15 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n",
      "[NeMo W 2022-05-31 14:19:15 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-05-31 14:19:15 features:200] PADDING: 0\n",
      "[NeMo I 2022-05-31 14:19:19 save_restore_connector:243] Model EncDecCTCModelBPE was successfully restored from /root/.cache/torch/NeMo/NeMo_1.10.0rc0/stt_en_conformer_ctc_large/010120d9959425c7862c9843960b3235/stt_en_conformer_ctc_large.nemo.\n"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "asr_model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(model_name=\"stt_en_conformer_ctc_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', 's', '▁', 'e', 't', 'u', 'd', 'a', 'o', 'n', 'i', '▁the', '▁a', 'm', 'y', 'l', 'h', 'p', 're', '▁s', 'g', 'r', '▁to', '▁i', 'ing', '▁and', 'f', '▁p', 'an', 'c', 'w', 'er', 'ed', '▁of', '▁in', 'k', \"'\", '▁w', 'ar', 'or', '▁f', 'b', '▁b', 'en', '▁you', 'al', 'le', 'in', 'll', '▁that', '▁he', 'ro', '▁t', 'es', '▁it', '▁be', 've', 'v', 'ly', '▁c', 'th', '▁o', 'ent', 'ch', 'ur', '▁we', '▁re', '▁n', 'it', '▁so', '▁co', '▁g', '▁on', '▁for', 'on', 'ce', 'ri', '▁do', '▁is', '▁ha', '▁ma', 'ver', 'li', 'ra', '▁was', 'ic', 'la', '▁e', 'se', 'ter', 'ct', 'ion', '▁ca', '▁st', '▁me', 'ir', '▁mo', '▁with', '▁but', '▁have', '▁go', '▁de', '▁ho', '▁di', '▁not', '▁know', '▁lo', '▁this', 'ation', 'ther', 'ate', '▁com', '▁like', '▁uh', 'ck', '▁his', 'j', '▁yeah', '▁my', '▁ex', '▁what', '▁will', '▁mi', 'q', 'ight', 'x', 'z', '-']\n"
     ]
    }
   ],
   "source": [
    "# Check what kind of vocabulary/alphabet the model has right now\n",
    "print(asr_model.decoder.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(asr_model.decoder.vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BBtk30g5sHJ"
   },
   "source": [
    "Now let's update the vocabulary in this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4Ey9CUkJ5o56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-05-31 14:19:19 modelPT:215] You tried to register an artifact under config key=tokenizer.model_path but an artifact for it has already been registered.\n",
      "[NeMo W 2022-05-31 14:19:19 modelPT:215] You tried to register an artifact under config key=tokenizer.vocab_path but an artifact for it has already been registered.\n",
      "[NeMo W 2022-05-31 14:19:19 modelPT:215] You tried to register an artifact under config key=tokenizer.spe_tokenizer_vocab but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-05-31 14:19:19 mixins:166] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2022-05-31 14:19:19 ctc_bpe_models:244] \n",
      "    Replacing old number of classes (128) with new number of classes - 1024\n",
      "[NeMo I 2022-05-31 14:19:19 ctc_bpe_models:273] Changed tokenizer to ['<unk>', 'en', 'er', 'ch', '▁d', 'ei', 'ie', '▁s', 'un', '▁a', '▁w', '▁i', 'st', 'ein', 'ge', '▁die', 'ich', '▁b', '▁m', 'an', '▁un', 'te', '▁v', 'sch', '▁h', '▁da', 'es', '▁n', 'on', '▁z', '▁k', '▁f', '▁der', 'in', '▁ein', '▁au', 'gen', '▁und', 'it', 'll', 'or', 'ur', '▁in', 'ar', 'ss', 'at', '▁ge', 'ir', 'hr', 'ung', '▁er', 'ten', '▁g', 'em', 'den', 'al', '▁zu', 'au', '▁l', 'der', '▁p', 'icht', 'de', '▁wir', '▁r', '▁ver', 'lich', 'ter', '▁be', '▁an', '▁das', 'ig', 'ber', 'ier', 'isch', 'ür', '▁ist', '▁e', 'ach', 'ben', '▁t', 'eit', 'mm', '▁den', 'se', '▁sie', 'ion', '▁sch', '▁mit', 'tz', '▁nicht', '▁j', '▁auf', '▁es', '▁st', 'ent', 'el', 'ol', 'ra', 'um', 'ro', '▁auch', '▁ich', '▁von', 'ck', '▁so', 're', 'ft', '▁sich', '▁al', 'and', 'ann', '▁für', 'am', '▁dies', '▁eine', '▁aus', '▁des', 'eu', '▁ko', '▁sein', 'is', 'rei', 'kt', '▁dass', 'hn', '▁im', 'le', '▁wer', '▁vor', 'op', '▁ha', 'ehr', '▁re', 'über', 'och', '▁als', 'ischen', '▁war', '▁o', 'sp', 'be', '▁dem', 'ind', 'ste', 'än', 'il', 'ssen', 'as', 'hm', '▁eur', '▁bei', 'lle', 'chen', '▁wie', 'ff', '▁hat', 'ungen', 'wei', '▁werden', 'nen', '▁über', '▁um', 'cht', '▁ihr', '▁nach', '▁europ', '▁sind', 'hl', 'rau', 'iel', 'hen', 'ahr', 'ne', '▁her', '▁haben', 'llen', 'ik', 'mmen', 'scha', '▁wur', 'ag', '▁unter', '▁aber', '▁uns', 'sten', 'ort', 'lie', '▁ab', '▁sp', 'ien', '▁ent', '▁wei', 'anz', '▁ber', 'ut', 'ische', 'aus', '▁wird', 'ger', '▁je', 'ri', 'rä', 'hal', 'zu', 'lei', '▁wen', 'uss', 'ation', 'end', 'ün', 'ver', '▁ar', 'iss', 'schaft', 'ige', 'gt', '▁diese', 'igen', '▁gr', 'ön', '▁le', '▁europä', '▁wo', 'ern', 'la', 'urch', '▁wurde', 'tzt', '▁noch', '▁all', 'ungs', '▁komm', 'rie', 'sen', 'eil', 'ör', '▁kon', '▁man', 'ät', '▁zur', 'und', '▁zwei', '▁ste', '▁pro', '▁mehr', '▁hier', '▁einen', '▁nur', 'us', '▁durch', 'tw', '▁kön', 'eine', 'ht', 'bt', 'iv', 'är', 'ru', 'ück', 'he', 'her', 'om', '▁wenn', '▁mü', 'ul', 'heit', 'chte', 'ken', 'fen', 'hmen', '▁kl', 'tet', 'schen', 'dern', 'iert', 'ing', 'ang', 'ab', '▁einer', '▁herr', '▁se', 'lichen', '▁was', '▁zum', 'lo', '▁dar', '▁dieser', '▁par', 'bei', 'mit', 'rit', 'keit', 'ster', '▁lie', 'ieren', '▁kann', 'che', '▁hin', 'aat', '▁bes', 'ad', '▁we', '▁gew', 'ühr', 'ko', '▁am', 'liche', 'ere', '▁jahr', '▁müssen', 'mal', '▁ander', 'ick', '▁mö', '▁kommiss', '▁gem', 'we', 'ot', 'gel', 'olit', 'pf', '▁ihn', 'wer', 'tel', '▁sehr', 'eut', '▁wi', 'mmer', '▁dann', 'ffen', '▁c', '▁gen', 'si', 'sam', '▁weiter', '▁soll', '▁können', 'ßen', 'all', '▁fra', '▁sa', 'bl', '▁gegen', 'beit', '▁einem', 'geb', 'sa', 'ahl', '▁oder', '▁en', '▁zw', 'bar', 'acht', '▁men', '▁gro', 'del', 'schl', 'for', '▁wieder', '▁muss', 'det', '▁fin', 'dent', '▁wel', '▁ei', '▁europäischen', 'eich', '▁ne', '▁gi', '▁seine', '▁ganz', 'na', '▁verb', 'eute', '▁bet', '▁ger', 'zi', '▁neu', 'ass', 'gr', '▁\"', 'ze', 'lau', 'räsi', '▁mein', 'ord', 'imm', 'dem', 'setz', 'ran', '▁deut', '▁bis', 'ähr', 'glie', '▁hatte', 'ess', '▁alle', '▁zeit', 'äch', 'ke', 'og', 'rin', '▁kommission', 'glich', 'pt', 'ktion', '▁ihre', '▁frau', 'ner', '▁jetzt', '▁viel', 'lam', 'zen', 'ierung', 'ist', 'kommen', '▁gibt', 'stell', '▁sel', 'ichtig', '▁ja', '▁menschen', '▁diesem', 'äu', 'räsident', '▁reg', '▁heute', 'os', '▁gef', '▁europa', '▁gesch', '▁gemein', 'achen', 'rat', '▁kolle', 'aaten', '▁daß', '▁mitglie', 'pp', 'innen', '▁mich', '▁gel', 'leich', '▁geb', '▁ihm', '▁son', '▁ange', 'ität', '▁inter', 'tschaft', 'andel', '▁land', '▁ch', '▁parlam', '▁recht', 'hör', 'ok', 'rü', '▁erf', 'utz', '▁vert', 'bst', 'eiten', '▁dieses', 'alt', '▁immer', '▁parlament', 'ßer', '▁lei', 'igkeit', '▁keine', 'est', '▁mitglied', 'et', '▁schon', 'du', '▁ma', 'kte', '▁denn', '▁eigen', 'ha', '▁la', '▁arbeit', 'qu', '▁vie', '▁for', '▁drei', 'dert', '▁ho', '▁ges', '▁eu', '▁zusa', 'schie', 'olitik', 'mp', '▁kein', '▁eben', '▁bür', '▁damit', 'iz', 'halb', 'ale', '▁mir', 'änd', '▁zusammen', 'men', '▁präsident', '▁habe', 'ant', 'lin', '▁dan', '▁unser', '▁seiner', '▁beg', '▁ö', 'art', '▁wurden', 'atz', 'äl', 'halt', 'ers', '▁doch', 'ße', '▁bef', 'alen', '▁du', '▁europäische', '▁fl', 'zeit', '▁etw', '▁leben', '▁de', 'ionen', '▁brau', 'tes', 'gend', 'fer', 'halten', 'rag', 'oll', 'ill', 'fl', 'ma', 'fe', 'staaten', '▁union', '▁bürger', '▁selbst', '▁möchte', 'onder', 'führ', 'iger', '▁schw', '▁besch', '▁teil', '▁diesen', 'teil', '▁wirk', '▁te', 'hin', '▁ins', 'spiel', 'hne', '▁waren', 'nung', 'land', '▁sicher', 'adt', 'rach', 'ierte', '▁bericht', 'rechen', '▁geht', 'angen', 'wick', '▁wollen', 'nehmen', 'wir', '▁sol', 'änder', '▁grund', 'ho', 'vor', 'stand', '▁wor', 'att', '▁jed', 'ud', 'für', '▁rat', '▁dort', 'annt', '▁ausge', '▁„', 'ließ', '▁nun', '▁ro', '▁verf', '▁entsch', '▁haus', '▁bek', 'ga', 'je', 'ütz', '▁nat', '▁mitgliedstaaten', 'me', 'sel', 'ischer', '▁sondern', '▁nie', '▁ihnen', '▁sei', 'dung', '▁ob', '▁pl', 'uch', 'aupt', '▁welt', 'hem', 'stimm', 'tt', '▁wichtig', 'sk', '▁fol', '▁glau', 'itz', 'ften', 'ätz', 'enz', '▁dabei', '▁mar', '▁gu', '▁vier', '▁hei', '▁machen', '▁frei', 'tete', '▁gleich', '▁bez', '▁einge', 'ahren', '▁fa', '▁führ', '▁rei', '▁spiel', 'reich', '▁eines', '▁möglich', '▁dazu', 'nte', '▁aller', '▁darau', '▁unsere', '▁verw', '▁erw', '▁weil', '▁gehör', '▁wirtschaft', '▁dafür', '▁frage', '▁etwas', '▁sagen', 'ade', '▁stra', '▁kam', 'blem', '▁bereit', '▁viele', '▁sag', '▁fün', '▁entwick', '▁zurück', '▁brauchen', 'gte', 'weise', '▁verh', '▁meine', 'nis', '▁anderen', '▁wür', '▁gemeinsam', 'wo', 'ug', '▁jedoch', 'ert', 'lung', 'ler', '▁ohne', 'ding', 'unden', '▁einz', 'elt', '▁unterst', '▁richt', '▁fünf', '▁klar', '▁letz', '▁or', '▁bl', '▁abge', 'sicht', 'kl', '▁wirklich', 'ständ', 'ap', 'sche', '▁schl', '▁erfol', '▁finanz', 'net', '▁ihrer', 'okrat', 'ritt', 'igt', '▁zwischen', 'ive', '▁will', 'str', 'tern', 'wie', '▁ex', 'ser', '▁sozi', 'fall', 'uß', '▁bin', 'geben', '▁vom', '▁problem', 'ander', '▁einmal', 'äre', 'auf', '▁ta', 'ange', '▁verl', '▁gut', '▁darauf', 'unkt', '▁mittel', 'inn', '▁bede', '▁deshalb', 'id', '▁kollegen', '▁seinen', 'ragen', '▁handel', 'gung', '▁em', 'form', 'fach', '▁wissen', '▁na', 'bil', 'ffe', 'erst', 'ker', 'ahn', 'anden', 'ult', '▁me', '▁vers', 'ähl', 'setzt', '▁alles', 'urg', 'öl', 'äter', 'legen', '▁besonder', '▁stadt', '▁hal', '▁also', 'äm', '▁außer', '▁min', '▁fre', 'bau', '▁bil', '▁gest', '▁erst', 'ater', '▁tun', '▁einige', 'gem', 'twort', '▁sollte', '▁liegt', 'kun', '▁nation', 'mus', 'kehr', 'ös', '▁kur', 'ffent', '▁zahl', 'cher', 'spro', 'agt', '▁mal', '▁gerade', '▁nichts', 'stellt', '▁ihren', 'esen', 'ition', 'ürlich', 'ausend', '▁sy', 'pl', '▁bau', 'stem', '▁di', '▁sollten', 'ald', '▁währ', '▁star', '▁ra', '▁polit', '▁regel', '▁kin', '▁andere', 'richt', '▁ersten', 'gie', '▁sagte', 'mar', '▁seit', '▁jahren', '▁klein', 'dr', '▁', 'e', 'n', 'i', 'r', 's', 't', 'a', 'd', 'h', 'u', 'l', 'g', 'c', 'm', 'o', 'b', 'w', 'f', 'k', 'z', '.', 'p', 'v', ',', 'ü', 'ä', 'ö', 'j', 'ß', 'y', '-', '\"', 'x', '!', '?', 'q', '„', '“', \"'\", ':', '’', 'á', '–', '2', ';', '0', '—', 'í', 'ó', 'š', 'ō', '1', 'ğ', 'č', 'é', '»', 'ł', '«', '3', '5', 'ć', 'ñ', 'ş', '‘', '7', 'ř', '‚', 'ø', 'ú', 'ı', 'â', '9', 'ž', '8', 'ý', '4', '&', 'ô', 'ă', 'ã', 'ū', 'ș', 'ā', '́', 'ë', 'ń', 'è', 'ê', 'ç', 'ī', 'ě', 'ʿ', '6', 'đ', 'ś', 'å', '”', 'ň', 'ə', 'æ', 'ï', 'ę', 'ė', 'ț', 'œ', '′', 'à', 'î', 'ð', 'ą', '̇', '°', 'ż', 'ò', 'ő', '=', 'ů', 'ʻ', '‹', '›', '−', 'ġ', 'ņ', 'ź', 'а', 'и', 'о', 'ḫ', '‟', '`', 'ì', 'õ', 'û', 'ď', 'ľ', 'ţ', 'ť', '̧', 'в', 'е', 'м', 'р', 'с', 'ф', 'ш', 'ṣ', 'ả', 'ế', '$', '(', ')', '+', '[', ']', '¡', 'ù', 'þ', 'ē', 'ħ', 'İ', 'ŏ', 'ǐ', 'ˊ', 'μ', 'к', 'ч', 'ӧ', '་', 'ན', 'ṟ', 'ṭ', 'ạ', 'ắ', 'ễ', 'ộ', '‐', '→', '≡', '─', '⟨', '⟩', 'カ', '临', '孙', '尣', '支', '無', '臣', '道'] vocabulary.\n"
     ]
    }
   ],
   "source": [
    "# Lets change the tokenizer vocabulary by passing the path to the new directory,\n",
    "# and also change the type\n",
    "asr_model.change_vocabulary(\n",
    "    new_tokenizer_dir=\"../data_preparation/data/processed/tokenizer/tokenizer_spe_bpe_v1024/\",\n",
    "    new_tokenizer_type=\"bpe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZ3sf2P26SiA"
   },
   "source": [
    "After this, our decoder has completely changed, but our encoder (where most of the weights are) remained intact. Let's fine tune-this model for 20 epochs on AN4 dataset. We will also use the smaller learning rate from ``new_opt` (see the \"After Training\" section)`.\n",
    "\n",
    "**Note**: For this demonstration, we will also freeze the encoder to speed up finetuning (since both tokenizers are built on the same train set), but in general it should not be done for proper training on a new language (or on a different corpus than the original train corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokenizer_cfg': {},\n",
       " 'tokenizer_dir': '../data_preparation/data/processed/tokenizer/tokenizer_spe_bpe_v1024/',\n",
       " 'tokenizer_type': 'bpe',\n",
       " 'hf_tokenizer_kwargs': {},\n",
       " 'artifacts': {'tokenizer.model_path': ArtifactItem(path='/localhome/local-vinhn/riva-german-sample-new/New-language-adaptation/German/data_preparation/data/processed/tokenizer/tokenizer_spe_bpe_v1024/tokenizer.model', path_type=<ArtifactPathType.LOCAL_PATH: 0>, hashed_path=None),\n",
       "  'tokenizer.vocab_path': ArtifactItem(path='/localhome/local-vinhn/riva-german-sample-new/New-language-adaptation/German/data_preparation/data/processed/tokenizer/tokenizer_spe_bpe_v1024/vocab.txt', path_type=<ArtifactPathType.LOCAL_PATH: 0>, hashed_path=None),\n",
       "  'tokenizer.spe_tokenizer_vocab': ArtifactItem(path='/localhome/local-vinhn/riva-german-sample-new/New-language-adaptation/German/data_preparation/data/processed/tokenizer/tokenizer_spe_bpe_v1024/tokenizer.vocab', path_type=<ArtifactPathType.LOCAL_PATH: 0>, hashed_path=None)},\n",
       " 'model_path': '/localhome/local-vinhn/riva-german-sample-new/New-language-adaptation/German/data_preparation/data/processed/tokenizer/tokenizer_spe_bpe_v1024/tokenizer.model',\n",
       " 'tokenizer': <nemo.collections.common.tokenizers.sentencepiece_tokenizer.SentencePieceTokenizer at 0x7f159d9d6b50>,\n",
       " 'vocab_path': '/localhome/local-vinhn/riva-german-sample-new/New-language-adaptation/German/data_preparation/data/processed/tokenizer/tokenizer_spe_bpe_v1024/vocab.txt',\n",
       " 'spe_vocab_path': '/localhome/local-vinhn/riva-german-sample-new/New-language-adaptation/German/data_preparation/data/processed/tokenizer/tokenizer_spe_bpe_v1024/tokenizer.vocab',\n",
       " 'world_size': 1,\n",
       " 'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict([(0,\n",
       "               <function torch.distributed._sharded_tensor.state_dict_hook(module, destination, prefix, local_metadata)>)]),\n",
       " '_load_state_dict_pre_hooks': OrderedDict([(1,\n",
       "               functools.partial(<function pre_load_state_dict_hook at 0x7f159da9bd30>, EncDecCTCModelBPE(\n",
       "                 (preprocessor): AudioToMelSpectrogramPreprocessor(\n",
       "                   (featurizer): FilterbankFeatures()\n",
       "                 )\n",
       "                 (encoder): ConformerEncoder(\n",
       "                   (pre_encode): ConvSubsampling(\n",
       "                     (out): Linear(in_features=10240, out_features=512, bias=True)\n",
       "                     (conv): Sequential(\n",
       "                       (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "                       (1): ReLU()\n",
       "                       (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "                       (3): ReLU()\n",
       "                     )\n",
       "                   )\n",
       "                   (pos_enc): RelPositionalEncoding(\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                   )\n",
       "                   (layers): ModuleList(\n",
       "                     (0): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (1): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (2): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (3): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (4): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (5): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (6): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (7): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (8): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (9): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (10): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (11): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (12): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (13): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (14): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (15): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (16): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                     (17): ConformerLayer(\n",
       "                       (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward1): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (conv): ConformerConvolution(\n",
       "                         (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                         (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                         (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                         (activation): Swish()\n",
       "                         (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                       )\n",
       "                       (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (self_attn): RelPositionMultiHeadAttention(\n",
       "                         (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                       )\n",
       "                       (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward2): ConformerFeedForward(\n",
       "                         (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                         (activation): Swish()\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     )\n",
       "                   )\n",
       "                 )\n",
       "                 (spec_augmentation): SpectrogramAugmentation(\n",
       "                   (spec_augment): SpecAugment()\n",
       "                 )\n",
       "                 (_wer): WERBPE()\n",
       "                 (decoder): ConvASRDecoder(\n",
       "                   (decoder_layers): Sequential(\n",
       "                     (0): Conv1d(512, 1025, kernel_size=(1,), stride=(1,))\n",
       "                   )\n",
       "                 )\n",
       "                 (loss): CTCLoss()\n",
       "               )))]),\n",
       " '_modules': OrderedDict([('preprocessor',\n",
       "               AudioToMelSpectrogramPreprocessor(\n",
       "                 (featurizer): FilterbankFeatures()\n",
       "               )),\n",
       "              ('encoder',\n",
       "               ConformerEncoder(\n",
       "                 (pre_encode): ConvSubsampling(\n",
       "                   (out): Linear(in_features=10240, out_features=512, bias=True)\n",
       "                   (conv): Sequential(\n",
       "                     (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "                     (1): ReLU()\n",
       "                     (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "                     (3): ReLU()\n",
       "                   )\n",
       "                 )\n",
       "                 (pos_enc): RelPositionalEncoding(\n",
       "                   (dropout): Dropout(p=0.1, inplace=False)\n",
       "                 )\n",
       "                 (layers): ModuleList(\n",
       "                   (0): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (1): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (2): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (3): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (4): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (5): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (6): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (7): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (8): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (9): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (10): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (11): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (12): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (13): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (14): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (15): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (16): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                   (17): ConformerLayer(\n",
       "                     (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward1): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (conv): ConformerConvolution(\n",
       "                       (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "                       (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
       "                       (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (activation): Swish()\n",
       "                       (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                     )\n",
       "                     (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (self_attn): RelPositionMultiHeadAttention(\n",
       "                       (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "                     )\n",
       "                     (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward2): ConformerFeedForward(\n",
       "                       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                       (activation): Swish()\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                   )\n",
       "                 )\n",
       "               )),\n",
       "              ('spec_augmentation',\n",
       "               SpectrogramAugmentation(\n",
       "                 (spec_augment): SpecAugment()\n",
       "               )),\n",
       "              ('_wer', WERBPE()),\n",
       "              ('decoder',\n",
       "               ConvASRDecoder(\n",
       "                 (decoder_layers): Sequential(\n",
       "                   (0): Conv1d(512, 1025, kernel_size=(1,), stride=(1,))\n",
       "                 )\n",
       "               )),\n",
       "              ('loss', CTCLoss())]),\n",
       " 'prepare_data_per_node': True,\n",
       " 'allow_zero_length_dataloader_with_multiple_devices': False,\n",
       " '_log_hyperparams': True,\n",
       " '_dtype': torch.float32,\n",
       " '_device': device(type='cuda'),\n",
       " 'trainer': None,\n",
       " '_use_amp': False,\n",
       " 'precision': 32,\n",
       " '_example_input_array': None,\n",
       " '_current_fx_name': None,\n",
       " '_automatic_optimization': True,\n",
       " '_truncated_bptt_steps': 0,\n",
       " '_param_requires_grad_state': {},\n",
       " '_metric_attributes': None,\n",
       " '_should_prevent_trainer_and_dataloaders_deepcopy': False,\n",
       " '_running_torchscript': False,\n",
       " '_cfg': {'sample_rate': 16000, 'log_prediction': True, 'ctc_reduction': 'mean_batch', 'train_ds': {'manifest_filepath': '/data/NeMo_ASR_SET/English/v2.0/train/tarred_audio_manifest.json', 'sample_rate': 16000, 'batch_size': 32, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'trim_silence': False, 'max_duration': 20.0, 'min_duration': 0.1, 'shuffle_n': 2048, 'is_tarred': True, 'tarred_audio_filepaths': '/data/NeMo_ASR_SET/English/v2.0/train/audio__OP_0..4095_CL_.tar'}, 'validation_ds': {'manifest_filepath': ['/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json'], 'sample_rate': 16000, 'batch_size': 16, 'shuffle': False, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'is_tarred': False, 'tarred_audio_filepaths': 'na'}, 'test_ds': {'manifest_filepath': ['/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json'], 'sample_rate': 16000, 'batch_size': 16, 'shuffle': False, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'is_tarred': False, 'tarred_audio_filepaths': 'na'}, 'tokenizer': {'dir': '../data_preparation/data/processed/tokenizer/tokenizer_spe_bpe_v1024/', 'type': 'bpe', 'model_path': '/localhome/local-vinhn/riva-german-sample-new/New-language-adaptation/German/data_preparation/data/processed/tokenizer/tokenizer_spe_bpe_v1024/tokenizer.model', 'vocab_path': '/localhome/local-vinhn/riva-german-sample-new/New-language-adaptation/German/data_preparation/data/processed/tokenizer/tokenizer_spe_bpe_v1024/vocab.txt', 'spe_tokenizer_vocab': '/localhome/local-vinhn/riva-german-sample-new/New-language-adaptation/German/data_preparation/data/processed/tokenizer/tokenizer_spe_bpe_v1024/tokenizer.vocab'}, 'preprocessor': {'_target_': 'nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor', 'sample_rate': 16000, 'normalize': 'per_feature', 'window_size': 0.025, 'window_stride': 0.01, 'window': 'hann', 'features': 80, 'n_fft': 512, 'log': True, 'frame_splicing': 1, 'dither': 1e-05, 'pad_to': 0, 'pad_value': 0.0}, 'spec_augment': {'_target_': 'nemo.collections.asr.modules.SpectrogramAugmentation', 'freq_masks': 2, 'time_masks': 10, 'freq_width': 27, 'time_width': 0.05}, 'encoder': {'_target_': 'nemo.collections.asr.modules.ConformerEncoder', 'feat_in': 80, 'feat_out': -1, 'n_layers': 18, 'd_model': 512, 'subsampling': 'striding', 'subsampling_factor': 4, 'subsampling_conv_channels': 512, 'ff_expansion_factor': 4, 'self_attention_model': 'rel_pos', 'n_heads': 8, 'att_context_size': [-1, -1], 'xscaling': True, 'untie_biases': True, 'pos_emb_max_len': 5000, 'conv_kernel_size': 31, 'dropout': 0.1, 'dropout_emb': 0.0, 'dropout_att': 0.1}, 'decoder': {'_target_': 'nemo.collections.asr.modules.ConvASRDecoder', 'feat_in': 512, 'num_classes': 1024, 'vocabulary': ['<unk>', 'en', 'er', 'ch', '▁d', 'ei', 'ie', '▁s', 'un', '▁a', '▁w', '▁i', 'st', 'ein', 'ge', '▁die', 'ich', '▁b', '▁m', 'an', '▁un', 'te', '▁v', 'sch', '▁h', '▁da', 'es', '▁n', 'on', '▁z', '▁k', '▁f', '▁der', 'in', '▁ein', '▁au', 'gen', '▁und', 'it', 'll', 'or', 'ur', '▁in', 'ar', 'ss', 'at', '▁ge', 'ir', 'hr', 'ung', '▁er', 'ten', '▁g', 'em', 'den', 'al', '▁zu', 'au', '▁l', 'der', '▁p', 'icht', 'de', '▁wir', '▁r', '▁ver', 'lich', 'ter', '▁be', '▁an', '▁das', 'ig', 'ber', 'ier', 'isch', 'ür', '▁ist', '▁e', 'ach', 'ben', '▁t', 'eit', 'mm', '▁den', 'se', '▁sie', 'ion', '▁sch', '▁mit', 'tz', '▁nicht', '▁j', '▁auf', '▁es', '▁st', 'ent', 'el', 'ol', 'ra', 'um', 'ro', '▁auch', '▁ich', '▁von', 'ck', '▁so', 're', 'ft', '▁sich', '▁al', 'and', 'ann', '▁für', 'am', '▁dies', '▁eine', '▁aus', '▁des', 'eu', '▁ko', '▁sein', 'is', 'rei', 'kt', '▁dass', 'hn', '▁im', 'le', '▁wer', '▁vor', 'op', '▁ha', 'ehr', '▁re', 'über', 'och', '▁als', 'ischen', '▁war', '▁o', 'sp', 'be', '▁dem', 'ind', 'ste', 'än', 'il', 'ssen', 'as', 'hm', '▁eur', '▁bei', 'lle', 'chen', '▁wie', 'ff', '▁hat', 'ungen', 'wei', '▁werden', 'nen', '▁über', '▁um', 'cht', '▁ihr', '▁nach', '▁europ', '▁sind', 'hl', 'rau', 'iel', 'hen', 'ahr', 'ne', '▁her', '▁haben', 'llen', 'ik', 'mmen', 'scha', '▁wur', 'ag', '▁unter', '▁aber', '▁uns', 'sten', 'ort', 'lie', '▁ab', '▁sp', 'ien', '▁ent', '▁wei', 'anz', '▁ber', 'ut', 'ische', 'aus', '▁wird', 'ger', '▁je', 'ri', 'rä', 'hal', 'zu', 'lei', '▁wen', 'uss', 'ation', 'end', 'ün', 'ver', '▁ar', 'iss', 'schaft', 'ige', 'gt', '▁diese', 'igen', '▁gr', 'ön', '▁le', '▁europä', '▁wo', 'ern', 'la', 'urch', '▁wurde', 'tzt', '▁noch', '▁all', 'ungs', '▁komm', 'rie', 'sen', 'eil', 'ör', '▁kon', '▁man', 'ät', '▁zur', 'und', '▁zwei', '▁ste', '▁pro', '▁mehr', '▁hier', '▁einen', '▁nur', 'us', '▁durch', 'tw', '▁kön', 'eine', 'ht', 'bt', 'iv', 'är', 'ru', 'ück', 'he', 'her', 'om', '▁wenn', '▁mü', 'ul', 'heit', 'chte', 'ken', 'fen', 'hmen', '▁kl', 'tet', 'schen', 'dern', 'iert', 'ing', 'ang', 'ab', '▁einer', '▁herr', '▁se', 'lichen', '▁was', '▁zum', 'lo', '▁dar', '▁dieser', '▁par', 'bei', 'mit', 'rit', 'keit', 'ster', '▁lie', 'ieren', '▁kann', 'che', '▁hin', 'aat', '▁bes', 'ad', '▁we', '▁gew', 'ühr', 'ko', '▁am', 'liche', 'ere', '▁jahr', '▁müssen', 'mal', '▁ander', 'ick', '▁mö', '▁kommiss', '▁gem', 'we', 'ot', 'gel', 'olit', 'pf', '▁ihn', 'wer', 'tel', '▁sehr', 'eut', '▁wi', 'mmer', '▁dann', 'ffen', '▁c', '▁gen', 'si', 'sam', '▁weiter', '▁soll', '▁können', 'ßen', 'all', '▁fra', '▁sa', 'bl', '▁gegen', 'beit', '▁einem', 'geb', 'sa', 'ahl', '▁oder', '▁en', '▁zw', 'bar', 'acht', '▁men', '▁gro', 'del', 'schl', 'for', '▁wieder', '▁muss', 'det', '▁fin', 'dent', '▁wel', '▁ei', '▁europäischen', 'eich', '▁ne', '▁gi', '▁seine', '▁ganz', 'na', '▁verb', 'eute', '▁bet', '▁ger', 'zi', '▁neu', 'ass', 'gr', '▁\"', 'ze', 'lau', 'räsi', '▁mein', 'ord', 'imm', 'dem', 'setz', 'ran', '▁deut', '▁bis', 'ähr', 'glie', '▁hatte', 'ess', '▁alle', '▁zeit', 'äch', 'ke', 'og', 'rin', '▁kommission', 'glich', 'pt', 'ktion', '▁ihre', '▁frau', 'ner', '▁jetzt', '▁viel', 'lam', 'zen', 'ierung', 'ist', 'kommen', '▁gibt', 'stell', '▁sel', 'ichtig', '▁ja', '▁menschen', '▁diesem', 'äu', 'räsident', '▁reg', '▁heute', 'os', '▁gef', '▁europa', '▁gesch', '▁gemein', 'achen', 'rat', '▁kolle', 'aaten', '▁daß', '▁mitglie', 'pp', 'innen', '▁mich', '▁gel', 'leich', '▁geb', '▁ihm', '▁son', '▁ange', 'ität', '▁inter', 'tschaft', 'andel', '▁land', '▁ch', '▁parlam', '▁recht', 'hör', 'ok', 'rü', '▁erf', 'utz', '▁vert', 'bst', 'eiten', '▁dieses', 'alt', '▁immer', '▁parlament', 'ßer', '▁lei', 'igkeit', '▁keine', 'est', '▁mitglied', 'et', '▁schon', 'du', '▁ma', 'kte', '▁denn', '▁eigen', 'ha', '▁la', '▁arbeit', 'qu', '▁vie', '▁for', '▁drei', 'dert', '▁ho', '▁ges', '▁eu', '▁zusa', 'schie', 'olitik', 'mp', '▁kein', '▁eben', '▁bür', '▁damit', 'iz', 'halb', 'ale', '▁mir', 'änd', '▁zusammen', 'men', '▁präsident', '▁habe', 'ant', 'lin', '▁dan', '▁unser', '▁seiner', '▁beg', '▁ö', 'art', '▁wurden', 'atz', 'äl', 'halt', 'ers', '▁doch', 'ße', '▁bef', 'alen', '▁du', '▁europäische', '▁fl', 'zeit', '▁etw', '▁leben', '▁de', 'ionen', '▁brau', 'tes', 'gend', 'fer', 'halten', 'rag', 'oll', 'ill', 'fl', 'ma', 'fe', 'staaten', '▁union', '▁bürger', '▁selbst', '▁möchte', 'onder', 'führ', 'iger', '▁schw', '▁besch', '▁teil', '▁diesen', 'teil', '▁wirk', '▁te', 'hin', '▁ins', 'spiel', 'hne', '▁waren', 'nung', 'land', '▁sicher', 'adt', 'rach', 'ierte', '▁bericht', 'rechen', '▁geht', 'angen', 'wick', '▁wollen', 'nehmen', 'wir', '▁sol', 'änder', '▁grund', 'ho', 'vor', 'stand', '▁wor', 'att', '▁jed', 'ud', 'für', '▁rat', '▁dort', 'annt', '▁ausge', '▁„', 'ließ', '▁nun', '▁ro', '▁verf', '▁entsch', '▁haus', '▁bek', 'ga', 'je', 'ütz', '▁nat', '▁mitgliedstaaten', 'me', 'sel', 'ischer', '▁sondern', '▁nie', '▁ihnen', '▁sei', 'dung', '▁ob', '▁pl', 'uch', 'aupt', '▁welt', 'hem', 'stimm', 'tt', '▁wichtig', 'sk', '▁fol', '▁glau', 'itz', 'ften', 'ätz', 'enz', '▁dabei', '▁mar', '▁gu', '▁vier', '▁hei', '▁machen', '▁frei', 'tete', '▁gleich', '▁bez', '▁einge', 'ahren', '▁fa', '▁führ', '▁rei', '▁spiel', 'reich', '▁eines', '▁möglich', '▁dazu', 'nte', '▁aller', '▁darau', '▁unsere', '▁verw', '▁erw', '▁weil', '▁gehör', '▁wirtschaft', '▁dafür', '▁frage', '▁etwas', '▁sagen', 'ade', '▁stra', '▁kam', 'blem', '▁bereit', '▁viele', '▁sag', '▁fün', '▁entwick', '▁zurück', '▁brauchen', 'gte', 'weise', '▁verh', '▁meine', 'nis', '▁anderen', '▁wür', '▁gemeinsam', 'wo', 'ug', '▁jedoch', 'ert', 'lung', 'ler', '▁ohne', 'ding', 'unden', '▁einz', 'elt', '▁unterst', '▁richt', '▁fünf', '▁klar', '▁letz', '▁or', '▁bl', '▁abge', 'sicht', 'kl', '▁wirklich', 'ständ', 'ap', 'sche', '▁schl', '▁erfol', '▁finanz', 'net', '▁ihrer', 'okrat', 'ritt', 'igt', '▁zwischen', 'ive', '▁will', 'str', 'tern', 'wie', '▁ex', 'ser', '▁sozi', 'fall', 'uß', '▁bin', 'geben', '▁vom', '▁problem', 'ander', '▁einmal', 'äre', 'auf', '▁ta', 'ange', '▁verl', '▁gut', '▁darauf', 'unkt', '▁mittel', 'inn', '▁bede', '▁deshalb', 'id', '▁kollegen', '▁seinen', 'ragen', '▁handel', 'gung', '▁em', 'form', 'fach', '▁wissen', '▁na', 'bil', 'ffe', 'erst', 'ker', 'ahn', 'anden', 'ult', '▁me', '▁vers', 'ähl', 'setzt', '▁alles', 'urg', 'öl', 'äter', 'legen', '▁besonder', '▁stadt', '▁hal', '▁also', 'äm', '▁außer', '▁min', '▁fre', 'bau', '▁bil', '▁gest', '▁erst', 'ater', '▁tun', '▁einige', 'gem', 'twort', '▁sollte', '▁liegt', 'kun', '▁nation', 'mus', 'kehr', 'ös', '▁kur', 'ffent', '▁zahl', 'cher', 'spro', 'agt', '▁mal', '▁gerade', '▁nichts', 'stellt', '▁ihren', 'esen', 'ition', 'ürlich', 'ausend', '▁sy', 'pl', '▁bau', 'stem', '▁di', '▁sollten', 'ald', '▁währ', '▁star', '▁ra', '▁polit', '▁regel', '▁kin', '▁andere', 'richt', '▁ersten', 'gie', '▁sagte', 'mar', '▁seit', '▁jahren', '▁klein', 'dr', '▁', 'e', 'n', 'i', 'r', 's', 't', 'a', 'd', 'h', 'u', 'l', 'g', 'c', 'm', 'o', 'b', 'w', 'f', 'k', 'z', '.', 'p', 'v', ',', 'ü', 'ä', 'ö', 'j', 'ß', 'y', '-', '\"', 'x', '!', '?', 'q', '„', '“', \"'\", ':', '’', 'á', '–', '2', ';', '0', '—', 'í', 'ó', 'š', 'ō', '1', 'ğ', 'č', 'é', '»', 'ł', '«', '3', '5', 'ć', 'ñ', 'ş', '‘', '7', 'ř', '‚', 'ø', 'ú', 'ı', 'â', '9', 'ž', '8', 'ý', '4', '&', 'ô', 'ă', 'ã', 'ū', 'ș', 'ā', '́', 'ë', 'ń', 'è', 'ê', 'ç', 'ī', 'ě', 'ʿ', '6', 'đ', 'ś', 'å', '”', 'ň', 'ə', 'æ', 'ï', 'ę', 'ė', 'ț', 'œ', '′', 'à', 'î', 'ð', 'ą', '̇', '°', 'ż', 'ò', 'ő', '=', 'ů', 'ʻ', '‹', '›', '−', 'ġ', 'ņ', 'ź', 'а', 'и', 'о', 'ḫ', '‟', '`', 'ì', 'õ', 'û', 'ď', 'ľ', 'ţ', 'ť', '̧', 'в', 'е', 'м', 'р', 'с', 'ф', 'ш', 'ṣ', 'ả', 'ế', '$', '(', ')', '+', '[', ']', '¡', 'ù', 'þ', 'ē', 'ħ', 'İ', 'ŏ', 'ǐ', 'ˊ', 'μ', 'к', 'ч', 'ӧ', '་', 'ན', 'ṟ', 'ṭ', 'ạ', 'ắ', 'ễ', 'ộ', '‐', '→', '≡', '─', '⟨', '⟩', 'カ', '临', '孙', '尣', '支', '無', '臣', '道']}, 'optim': {'name': 'adamw', 'lr': 2.0, 'betas': [0.9, 0.98], 'weight_decay': 0.001, 'sched': {'name': 'NoamAnnealing', 'd_model': 512, 'warmup_steps': 10000, 'warmup_ratio': None, 'min_lr': 1e-06}}, 'target': 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE', 'nemo_version': '1.10.0rc0'},\n",
       " '_hparams_name': 'kwargs',\n",
       " '_hparams': \"cfg\": {'sample_rate': 16000, 'log_prediction': True, 'ctc_reduction': 'mean_batch', 'train_ds': {'manifest_filepath': '/data/NeMo_ASR_SET/English/v2.0/train/tarred_audio_manifest.json', 'sample_rate': 16000, 'batch_size': 32, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'trim_silence': False, 'max_duration': 20.0, 'min_duration': 0.1, 'shuffle_n': 2048, 'is_tarred': True, 'tarred_audio_filepaths': '/data/NeMo_ASR_SET/English/v2.0/train/audio__OP_0..4095_CL_.tar'}, 'validation_ds': {'manifest_filepath': ['/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json'], 'sample_rate': 16000, 'batch_size': 16, 'shuffle': False, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'is_tarred': False, 'tarred_audio_filepaths': 'na'}, 'test_ds': {'manifest_filepath': ['/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json'], 'sample_rate': 16000, 'batch_size': 16, 'shuffle': False, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'is_tarred': False, 'tarred_audio_filepaths': 'na'}, 'tokenizer': {'dir': '/tokenizers/NeMo_ASR_SET/English/asr_set_2.0/tokenizer_spe_unigram_v128/', 'type': 'bpe', 'model_path': 'nemo:eba1b3eaeb954624b16408eb64adb85a_tokenizer.model', 'vocab_path': 'nemo:98a23bf202634dab96ede2f43de77994_vocab.txt', 'spe_tokenizer_vocab': 'nemo:b5858ae29b984021aed220772ca1ff19_tokenizer.vocab'}, 'preprocessor': {'_target_': 'nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor', 'sample_rate': 16000, 'normalize': 'per_feature', 'window_size': 0.025, 'window_stride': 0.01, 'window': 'hann', 'features': 80, 'n_fft': 512, 'log': True, 'frame_splicing': 1, 'dither': 1e-05, 'pad_to': 0, 'pad_value': 0.0}, 'spec_augment': {'_target_': 'nemo.collections.asr.modules.SpectrogramAugmentation', 'freq_masks': 2, 'time_masks': 10, 'freq_width': 27, 'time_width': 0.05}, 'encoder': {'_target_': 'nemo.collections.asr.modules.ConformerEncoder', 'feat_in': 80, 'feat_out': -1, 'n_layers': 18, 'd_model': 512, 'subsampling': 'striding', 'subsampling_factor': 4, 'subsampling_conv_channels': 512, 'ff_expansion_factor': 4, 'self_attention_model': 'rel_pos', 'n_heads': 8, 'att_context_size': [-1, -1], 'xscaling': True, 'untie_biases': True, 'pos_emb_max_len': 5000, 'conv_kernel_size': 31, 'dropout': 0.1, 'dropout_emb': 0.0, 'dropout_att': 0.1}, 'decoder': {'_target_': 'nemo.collections.asr.modules.ConvASRDecoder', 'feat_in': 512, 'num_classes': 128, 'vocabulary': ['<unk>', 's', '▁', 'e', 't', 'u', 'd', 'a', 'o', 'n', 'i', '▁the', '▁a', 'm', 'y', 'l', 'h', 'p', 're', '▁s', 'g', 'r', '▁to', '▁i', 'ing', '▁and', 'f', '▁p', 'an', 'c', 'w', 'er', 'ed', '▁of', '▁in', 'k', \"'\", '▁w', 'ar', 'or', '▁f', 'b', '▁b', 'en', '▁you', 'al', 'le', 'in', 'll', '▁that', '▁he', 'ro', '▁t', 'es', '▁it', '▁be', 've', 'v', 'ly', '▁c', 'th', '▁o', 'ent', 'ch', 'ur', '▁we', '▁re', '▁n', 'it', '▁so', '▁co', '▁g', '▁on', '▁for', 'on', 'ce', 'ri', '▁do', '▁is', '▁ha', '▁ma', 'ver', 'li', 'ra', '▁was', 'ic', 'la', '▁e', 'se', 'ter', 'ct', 'ion', '▁ca', '▁st', '▁me', 'ir', '▁mo', '▁with', '▁but', '▁have', '▁go', '▁de', '▁ho', '▁di', '▁not', '▁know', '▁lo', '▁this', 'ation', 'ther', 'ate', '▁com', '▁like', '▁uh', 'ck', '▁his', 'j', '▁yeah', '▁my', '▁ex', '▁what', '▁will', '▁mi', 'q', 'ight', 'x', 'z', '-']}, 'optim': {'name': 'adamw', 'lr': 2.0, 'betas': [0.9, 0.98], 'weight_decay': 0.001, 'sched': {'name': 'NoamAnnealing', 'd_model': 512, 'warmup_steps': 10000, 'warmup_ratio': None, 'min_lr': 1e-06}}, 'target': 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'},\n",
       " '_hparams_initial': \"cfg\": {'sample_rate': 16000, 'log_prediction': True, 'ctc_reduction': 'mean_batch', 'train_ds': {'manifest_filepath': '/data/NeMo_ASR_SET/English/v2.0/train/tarred_audio_manifest.json', 'sample_rate': 16000, 'batch_size': 32, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'trim_silence': False, 'max_duration': 20.0, 'min_duration': 0.1, 'shuffle_n': 2048, 'is_tarred': True, 'tarred_audio_filepaths': '/data/NeMo_ASR_SET/English/v2.0/train/audio__OP_0..4095_CL_.tar'}, 'validation_ds': {'manifest_filepath': ['/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json'], 'sample_rate': 16000, 'batch_size': 16, 'shuffle': False, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'is_tarred': False, 'tarred_audio_filepaths': 'na'}, 'test_ds': {'manifest_filepath': ['/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json'], 'sample_rate': 16000, 'batch_size': 16, 'shuffle': False, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'is_tarred': False, 'tarred_audio_filepaths': 'na'}, 'tokenizer': {'dir': '/tokenizers/NeMo_ASR_SET/English/asr_set_2.0/tokenizer_spe_unigram_v128/', 'type': 'bpe', 'model_path': 'nemo:eba1b3eaeb954624b16408eb64adb85a_tokenizer.model', 'vocab_path': 'nemo:98a23bf202634dab96ede2f43de77994_vocab.txt', 'spe_tokenizer_vocab': 'nemo:b5858ae29b984021aed220772ca1ff19_tokenizer.vocab'}, 'preprocessor': {'_target_': 'nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor', 'sample_rate': 16000, 'normalize': 'per_feature', 'window_size': 0.025, 'window_stride': 0.01, 'window': 'hann', 'features': 80, 'n_fft': 512, 'log': True, 'frame_splicing': 1, 'dither': 1e-05, 'pad_to': 0, 'pad_value': 0.0}, 'spec_augment': {'_target_': 'nemo.collections.asr.modules.SpectrogramAugmentation', 'freq_masks': 2, 'time_masks': 10, 'freq_width': 27, 'time_width': 0.05}, 'encoder': {'_target_': 'nemo.collections.asr.modules.ConformerEncoder', 'feat_in': 80, 'feat_out': -1, 'n_layers': 18, 'd_model': 512, 'subsampling': 'striding', 'subsampling_factor': 4, 'subsampling_conv_channels': 512, 'ff_expansion_factor': 4, 'self_attention_model': 'rel_pos', 'n_heads': 8, 'att_context_size': [-1, -1], 'xscaling': True, 'untie_biases': True, 'pos_emb_max_len': 5000, 'conv_kernel_size': 31, 'dropout': 0.1, 'dropout_emb': 0.0, 'dropout_att': 0.1}, 'decoder': {'_target_': 'nemo.collections.asr.modules.ConvASRDecoder', 'feat_in': 512, 'num_classes': 128, 'vocabulary': ['<unk>', 's', '▁', 'e', 't', 'u', 'd', 'a', 'o', 'n', 'i', '▁the', '▁a', 'm', 'y', 'l', 'h', 'p', 're', '▁s', 'g', 'r', '▁to', '▁i', 'ing', '▁and', 'f', '▁p', 'an', 'c', 'w', 'er', 'ed', '▁of', '▁in', 'k', \"'\", '▁w', 'ar', 'or', '▁f', 'b', '▁b', 'en', '▁you', 'al', 'le', 'in', 'll', '▁that', '▁he', 'ro', '▁t', 'es', '▁it', '▁be', 've', 'v', 'ly', '▁c', 'th', '▁o', 'ent', 'ch', 'ur', '▁we', '▁re', '▁n', 'it', '▁so', '▁co', '▁g', '▁on', '▁for', 'on', 'ce', 'ri', '▁do', '▁is', '▁ha', '▁ma', 'ver', 'li', 'ra', '▁was', 'ic', 'la', '▁e', 'se', 'ter', 'ct', 'ion', '▁ca', '▁st', '▁me', 'ir', '▁mo', '▁with', '▁but', '▁have', '▁go', '▁de', '▁ho', '▁di', '▁not', '▁know', '▁lo', '▁this', 'ation', 'ther', 'ate', '▁com', '▁like', '▁uh', 'ck', '▁his', 'j', '▁yeah', '▁my', '▁ex', '▁what', '▁will', '▁mi', 'q', 'ight', 'x', 'z', '-']}, 'optim': {'name': 'adamw', 'lr': 2.0, 'betas': [0.9, 0.98], 'weight_decay': 0.001, 'sched': {'name': 'NoamAnnealing', 'd_model': 512, 'warmup_steps': 10000, 'warmup_ratio': None, 'min_lr': 1e-06}}, 'target': 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'},\n",
       " '_train_dl': None,\n",
       " '_validation_dl': None,\n",
       " '_test_dl': None,\n",
       " '_optimizer_param_groups': None,\n",
       " '_optimizer': None,\n",
       " '_scheduler': None,\n",
       " '_trainer': None,\n",
       " '_save_restore_connector': <nemo.core.connectors.save_restore_connector.SaveRestoreConnector at 0x7f15a3aad040>,\n",
       " 'model_guid': '41bbd3e3-b79f-4c05-8a0f-10044289d866',\n",
       " 'training_step': <FunctionWrapper at 0x7f159da5ec40 for method at 0x7f15a3fd8f80>,\n",
       " '_skip_nan_grad': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(asr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘configs’: File exists\n",
      "--2022-05-31 14:19:20--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/asr/conf/conformer/conformer_ctc_bpe.yaml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8205 (8.0K) [text/plain]\n",
      "Saving to: ‘configs/conformer_ctc_bpe.yaml.2’\n",
      "\n",
      "conformer_ctc_bpe.y 100%[===================>]   8.01K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-05-31 14:19:20 (51.9 MB/s) - ‘configs/conformer_ctc_bpe.yaml.2’ saved [8205/8205]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Grab the config we'll use in this example\n",
    "BRANCH='main'\n",
    "!mkdir configs\n",
    "!wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/asr/conf/conformer/conformer_ctc_bpe.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Conformer-CTC-BPE', 'model': {'sample_rate': 16000, 'log_prediction': True, 'ctc_reduction': 'mean_batch', 'skip_nan_grad': False, 'train_ds': {'manifest_filepath': '???', 'sample_rate': '${model.sample_rate}', 'batch_size': 16, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'trim_silence': False, 'max_duration': 16.7, 'min_duration': 0.1, 'is_tarred': False, 'tarred_audio_filepaths': None, 'shuffle_n': 2048, 'bucketing_strategy': 'synced_randomized', 'bucketing_batch_size': None}, 'validation_ds': {'manifest_filepath': '???', 'sample_rate': '${model.sample_rate}', 'batch_size': 16, 'shuffle': False, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False}, 'test_ds': {'manifest_filepath': None, 'sample_rate': '${model.sample_rate}', 'batch_size': 16, 'shuffle': False, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False}, 'tokenizer': {'dir': '???', 'type': 'bpe'}, 'preprocessor': {'_target_': 'nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor', 'sample_rate': '${model.sample_rate}', 'normalize': 'per_feature', 'window_size': 0.025, 'window_stride': 0.01, 'window': 'hann', 'features': 80, 'n_fft': 512, 'log': True, 'frame_splicing': 1, 'dither': 1e-05, 'pad_to': 0, 'pad_value': 0.0}, 'spec_augment': {'_target_': 'nemo.collections.asr.modules.SpectrogramAugmentation', 'freq_masks': 2, 'time_masks': 10, 'freq_width': 27, 'time_width': 0.05}, 'encoder': {'_target_': 'nemo.collections.asr.modules.ConformerEncoder', 'feat_in': '${model.preprocessor.features}', 'feat_out': -1, 'n_layers': 18, 'd_model': 512, 'subsampling': 'striding', 'subsampling_factor': 4, 'subsampling_conv_channels': -1, 'ff_expansion_factor': 4, 'self_attention_model': 'rel_pos', 'n_heads': 8, 'att_context_size': [-1, -1], 'xscaling': True, 'untie_biases': True, 'pos_emb_max_len': 5000, 'conv_kernel_size': 31, 'conv_norm_type': 'batch_norm', 'dropout': 0.1, 'dropout_emb': 0.0, 'dropout_att': 0.1}, 'decoder': {'_target_': 'nemo.collections.asr.modules.ConvASRDecoder', 'feat_in': None, 'num_classes': -1, 'vocabulary': []}, 'optim': {'name': 'adamw', 'lr': 2.0, 'betas': [0.9, 0.98], 'weight_decay': 0.001, 'sched': {'name': 'NoamAnnealing', 'd_model': '${model.encoder.d_model}', 'warmup_steps': 10000, 'warmup_ratio': None, 'min_lr': 1e-06}}}, 'trainer': {'devices': -1, 'num_nodes': 1, 'max_epochs': 1000, 'max_steps': None, 'val_check_interval': 1.0, 'accelerator': 'auto', 'strategy': 'ddp', 'accumulate_grad_batches': 1, 'gradient_clip_val': 0.0, 'precision': 32, 'log_every_n_steps': 10, 'progress_bar_refresh_rate': 10, 'resume_from_checkpoint': None, 'num_sanity_val_steps': 0, 'check_val_every_n_epoch': 1, 'sync_batchnorm': True, 'enable_checkpointing': False, 'logger': False, 'benchmark': False}, 'exp_manager': {'exp_dir': None, 'name': '${name}', 'create_tensorboard_logger': True, 'create_checkpoint_callback': True, 'checkpoint_callback_params': {'monitor': 'val_wer', 'mode': 'min', 'save_top_k': 5, 'always_save_nemo': True}, 'resume_if_exists': False, 'resume_ignore_no_checkpoint': False, 'create_wandb_logger': False, 'wandb_logger_kwargs': {'name': None, 'project': None}}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "with initialize(config_path=\"./configs/\"):\n",
    "    cfg = compose(config_name=\"conformer_ctc_bpe.yaml\")\n",
    "    print(cfg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Conformer-CTC-BPE\n",
      "model:\n",
      "  sample_rate: 16000\n",
      "  log_prediction: true\n",
      "  ctc_reduction: mean_batch\n",
      "  skip_nan_grad: false\n",
      "  train_ds:\n",
      "    manifest_filepath: ???\n",
      "    sample_rate: ${model.sample_rate}\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 16.7\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "  validation_ds:\n",
      "    manifest_filepath: ???\n",
      "    sample_rate: ${model.sample_rate}\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "  test_ds:\n",
      "    manifest_filepath: null\n",
      "    sample_rate: ${model.sample_rate}\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "  tokenizer:\n",
      "    dir: ???\n",
      "    type: bpe\n",
      "  preprocessor:\n",
      "    _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor\n",
      "    sample_rate: ${model.sample_rate}\n",
      "    normalize: per_feature\n",
      "    window_size: 0.025\n",
      "    window_stride: 0.01\n",
      "    window: hann\n",
      "    features: 80\n",
      "    n_fft: 512\n",
      "    log: true\n",
      "    frame_splicing: 1\n",
      "    dither: 1.0e-05\n",
      "    pad_to: 0\n",
      "    pad_value: 0.0\n",
      "  spec_augment:\n",
      "    _target_: nemo.collections.asr.modules.SpectrogramAugmentation\n",
      "    freq_masks: 2\n",
      "    time_masks: 10\n",
      "    freq_width: 27\n",
      "    time_width: 0.05\n",
      "  encoder:\n",
      "    _target_: nemo.collections.asr.modules.ConformerEncoder\n",
      "    feat_in: ${model.preprocessor.features}\n",
      "    feat_out: -1\n",
      "    n_layers: 18\n",
      "    d_model: 512\n",
      "    subsampling: striding\n",
      "    subsampling_factor: 4\n",
      "    subsampling_conv_channels: -1\n",
      "    ff_expansion_factor: 4\n",
      "    self_attention_model: rel_pos\n",
      "    n_heads: 8\n",
      "    att_context_size:\n",
      "    - -1\n",
      "    - -1\n",
      "    xscaling: true\n",
      "    untie_biases: true\n",
      "    pos_emb_max_len: 5000\n",
      "    conv_kernel_size: 31\n",
      "    conv_norm_type: batch_norm\n",
      "    dropout: 0.1\n",
      "    dropout_emb: 0.0\n",
      "    dropout_att: 0.1\n",
      "  decoder:\n",
      "    _target_: nemo.collections.asr.modules.ConvASRDecoder\n",
      "    feat_in: null\n",
      "    num_classes: -1\n",
      "    vocabulary: []\n",
      "  optim:\n",
      "    name: adamw\n",
      "    lr: 2.0\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.98\n",
      "    weight_decay: 0.001\n",
      "    sched:\n",
      "      name: NoamAnnealing\n",
      "      d_model: ${model.encoder.d_model}\n",
      "      warmup_steps: 10000\n",
      "      warmup_ratio: null\n",
      "      min_lr: 1.0e-06\n",
      "trainer:\n",
      "  devices: -1\n",
      "  num_nodes: 1\n",
      "  max_epochs: 1000\n",
      "  max_steps: null\n",
      "  val_check_interval: 1.0\n",
      "  accelerator: auto\n",
      "  strategy: ddp\n",
      "  accumulate_grad_batches: 1\n",
      "  gradient_clip_val: 0.0\n",
      "  precision: 32\n",
      "  log_every_n_steps: 10\n",
      "  progress_bar_refresh_rate: 10\n",
      "  resume_from_checkpoint: null\n",
      "  num_sanity_val_steps: 0\n",
      "  check_val_every_n_epoch: 1\n",
      "  sync_batchnorm: true\n",
      "  enable_checkpointing: false\n",
      "  logger: false\n",
      "  benchmark: false\n",
      "exp_manager:\n",
      "  exp_dir: null\n",
      "  name: ${name}\n",
      "  create_tensorboard_logger: true\n",
      "  create_checkpoint_callback: true\n",
      "  checkpoint_callback_params:\n",
      "    monitor: val_wer\n",
      "    mode: min\n",
      "    save_top_k: 5\n",
      "    always_save_nemo: true\n",
      "  resume_if_exists: false\n",
      "  resume_ignore_no_checkpoint: false\n",
      "  create_wandb_logger: false\n",
      "  wandb_logger_kwargs:\n",
      "    name: null\n",
      "    project: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'manifest_filepath': '???', 'sample_rate': '${model.sample_rate}', 'batch_size': 16, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'trim_silence': False, 'max_duration': 16.7, 'min_duration': 0.1, 'is_tarred': False, 'tarred_audio_filepaths': None, 'shuffle_n': 2048, 'bucketing_strategy': 'synced_randomized', 'bucketing_batch_size': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['model']['train_ds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample_rate = 16000\n",
      "The ds_sample_rate = 16000\n"
     ]
    }
   ],
   "source": [
    "sample_rate = cfg.model.sample_rate\n",
    "print(f\"The sample_rate = {sample_rate}\")\n",
    "\n",
    "ds_sample_rate = cfg.model.train_ds.sample_rate\n",
    "print(f\"The ds_sample_rate = {ds_sample_rate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = cfg\n",
    "\n",
    "import copy\n",
    "new_opt = copy.deepcopy(params.model.optim)\n",
    "new_opt.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update paths to dataset\n",
    "params.model.train_ds.manifest_filepath = '../data_preparation/data/processed/train_manifest_merged.json'\n",
    "params.model.train_ds.sample_rate = 16000\n",
    "params.model.train_ds.batch_size = 1\n",
    "\n",
    "params.model.validation_ds.manifest_filepath = ['../data_preparation/data/processed/test_manifest_merged.json', '../data_preparation/data/processed/dev_manifest_merged.json']\n",
    "params.model.validation_ds.sample_rate = 16000\n",
    "params.model.validation_ds.batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'manifest_filepath': '../data_preparation/data/processed/train_manifest_merged.json', 'sample_rate': 16000, 'batch_size': 1, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'trim_silence': False, 'max_duration': 16.7, 'min_duration': 0.1, 'is_tarred': False, 'tarred_audio_filepaths': None, 'shuffle_n': 2048, 'bucketing_strategy': 'synced_randomized', 'bucketing_batch_size': None}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['model']['train_ds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.model.encoder.d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "7m_CRtH46BjO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-05-31 14:55:26 modelPT:478] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-05-31 14:55:26 modelPT:579] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        eps: 1e-08\n",
      "        lr: 0.1\n",
      "        weight_decay: 0.001\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-05-31 14:55:26 lr_scheduler:816] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(AdamW (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: [0.9, 0.98]\n",
       "     eps: 1e-08\n",
       "     lr: 0.1\n",
       "     weight_decay: 0.001\n",
       " ),\n",
       " None)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the smaller learning rate we set before\n",
    "asr_model.setup_optimization(optim_config=new_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asr_model._cfg.optim.sched.d_model = params.model.encoder.d_model\n",
    "asr_model._cfg.optim.sched.d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "[NeMo I 2022-05-31 14:56:08 collections:192] Dataset loaded with 309291 files totalling 569.59 hours\n",
      "[NeMo I 2022-05-31 14:56:08 collections:193] 11862 files were filtered totalling 60.25 hours\n"
     ]
    }
   ],
   "source": [
    "params.model.optim.sched.d_model = params.model.encoder.d_model\n",
    "print(params.model.optim.sched.d_model)\n",
    "\n",
    "# Point to the data we'll use for fine-tuning as the training set\n",
    "asr_model._cfg.train_ds.sample_rate = 16000\n",
    "asr_model._cfg.validation_ds.sample_rate = 16000\n",
    "asr_model.setup_training_data(train_data_config=params.model.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-05-31 14:56:10 collections:192] Dataset loaded with 41167 files totalling 85.44 hours\n",
      "[NeMo I 2022-05-31 14:56:10 collections:193] 0 files were filtered totalling 0.00 hours\n"
     ]
    }
   ],
   "source": [
    "# Point to the new validation data for fine-tuning\n",
    "asr_model.setup_validation_data(val_data_config=params.model.validation_ds)\n",
    "\n",
    "# Freeze the encoder layers (should not be done for finetuning, only done for demo)\n",
    "asr_model.encoder.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s ../data_preparation/data data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "fs2aK7xB6pAd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo W 2022-05-31 14:56:13 modelPT:478] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-05-31 14:56:13 modelPT:579] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        eps: 1e-08\n",
      "        lr: 0.1\n",
      "        weight_decay: 0.001\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-05-31 14:56:13 lr_scheduler:816] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n",
      "\n",
      "  | Name              | Type                              | Params\n",
      "------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
      "1 | encoder           | ConformerEncoder                  | 121 M \n",
      "2 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
      "3 | _wer              | WERBPE                            | 0     \n",
      "4 | decoder           | ConvASRDecoder                    | 525 K \n",
      "5 | loss              | CTCLoss                           | 0     \n",
      "------------------------------------------------------------------------\n",
      "525 K     Trainable params\n",
      "121 M     Non-trainable params\n",
      "121 M     Total params\n",
      "487.844   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a6e71b4e0f4241ac8d85fa87c6cbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-05-31 14:56:15 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:15 wer_bpe:213] reference:denken sie soeben weilten meine gedanken bei ihnen in adelaide und ich wünschte mir sie herzaubern zu können nun der zauber ist gelungen lachte münchhausen da bin ich und was mich herführt\n",
      "[NeMo I 2022-05-31 14:56:15 wer_bpe:214] predicted:weu ichht bei war iche von vonuku wurdebeüen in warö war. niewwewerwewe war immerö rath warout\n",
      "[NeMo I 2022-05-31 14:56:15 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:15 wer_bpe:213] reference:also bei ihren technischen kenntnissen und ihrer erfindungsgabe auf diesem gebiet glaubt der lord keinen besseren ingenieur und kapitän für sein weltschiff finden zu können als sie\n",
      "[NeMo I 2022-05-31 14:56:15 wer_bpe:214] predicted:ich dabei vonö tünkdenünken arierenannüwehünwekokenlweüwebeweal nie sein dabeiieren keine dennannierenü an beihkße vonweheit arwecheisweüö in in jetztwefer seinferweferününöweundenfer valierenöüö ichfer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6d1ee5fc3a4a6296956ac504a942a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:213] reference:diese versammlung trifft sich regelmäßig im abstand von einem bis drei monate.\n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:214] predicted:die soeogandw le tbewe dieseweie hoischeie landenmonatachen beg\n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:213] reference:meistens stellt es asiatische motive oder ein tier dar.\n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:214] predicted:verwe verst tie vonandieren von.\n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:213] reference:parallel der strecke entstanden zahlreiche grubenbahnen, die die strecke kreuzten.\n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:214] predicted:ver. weiterck ver tigbe war regel tmmck war..\n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:213] reference:angeblich ist das aktuelle defizit dadurch von vier hundert sechs und vierzig millionen auf vier und sechzig millionen reduziert worden.\n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:214] predicted:jetztstätw mck ver v dermmstenatu.\n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:213] reference:der kriegsverlauf war maßgeblich durch den verrat der heerführer der sikh-armee geprägt.\n",
      "[NeMo I 2022-05-31 14:56:17 wer_bpe:214] predicted:ichäzenzßigsigmm migacheß siche lebenlungriat der ver veröigig ders einieruteteigt est..\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:213] reference:glaubt das ernsthaft jemand?\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:214] predicted:daseu dreiigt dietu von.\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:213] reference:sie dankte mir mit den worten gott befreie dich von jedem kummer wie du eben den meinigen zerstreut ich wollte schon wieder weitergehen da sprang sie auf mich zu küßte mir die hand und sagte\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:214] predicted:st einemte regelb esel mb vontenten, von derotaiercheu h h h ab h die madente die ste regel esß hischeteigri an stes... m oderack m einemuarß begztenstsib imu regel dreiz zahlig einemandig verßel die hel ab paru.\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:213] reference:damit war nigeria erneut für die olympischen spiele qualifiziert.\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:214] predicted:m m darf einig oderig oder war die vonslungig die vonun einemei spcku darpgebesiua aigte.te.te\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:213] reference:deshalb ist barcelona so überaus wichtig.\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:214] predicted:dermduft m imeen undunei\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:213] reference:bislang stehen nur freiwillige maßnahmen im mittelpunkt, und ich denke, so werden wir nur schwer der energieunion näher kommen.\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:214] predicted:und das einf darallftden dar von bisanden darandte, auff dabenßiertdurie stetente\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:213] reference:kaufst du echt bei tchibo klamotten ein?\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:214] predicted:erlich ge miert\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:213] reference:sie wird freiwillig geschlossen.\n",
      "[NeMo I 2022-05-31 14:56:18 wer_bpe:214] predicted:all und denlo\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:213] reference:was ist jetzt zur wiederherstellung dieses vertrauens zu tun?\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:214] predicted:weiterot abdgeb k reurch darot keft kllrei k m\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:213] reference:und da sollen sogar millionen forschungsgelder für einen sauberen diesel ausgegeben werden, wie ich kürzlich las, obwohl dessen totengeläut schon längst zu hören ist.\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:214] predicted:k k aurchben undeg ma undeuthh undivellg oder der kanden nktiert gch zuä kre auf\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:213] reference:das alles sind einige beispiele, wie wir die zukunft sehen.\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:214] predicted:s das undgie bei zer k undar ma\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:213] reference:seine eltern waren paul von breitenbach und dessen ehefrau christina johanna elvira von breitenbach.\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:214] predicted:dasp sobtichf zuionllikte zuarllg dench zu,rerieer d\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:213] reference:trägst du mich das letzte stück?\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:214] predicted:relich ein sie denge k?\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:213] reference:und sie haben sehr gute vorschläge, zum beispiel den praktischen nutzen der investierten gelder zu überprüfen und nicht nur formelle kriterien.\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:214] predicted:? bis jstlo enang wie?ut zg d mirlichi zu? istarst z sstlichielle wie wie wie zul klich ein wie werden an\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:213] reference:aber letztendlich müssen auch wir realisten sein.\n",
      "[NeMo I 2022-05-31 14:56:19 wer_bpe:214] predicted:arreizhen,ten s istar\n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:213] reference:sie wurden aber auch als dank nach erlöschen der pest aufgestellt.\n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:214] predicted:sie sielang, s ner soionllkte k sn vier da t derverchtä\n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:213] reference:es ist ebenso ein menschenrecht, dass die nachkommen wissen, wo ihre angehörigen die letzte ruhe gefunden haben, und freien zugang zu diesem ort erhalten.\n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:214] predicted:n  sie,n dendgt jischenarftarigelolotal wirherstellar so ist gemp n b mitktewerunktft ich b dan diese wirdiert nderutführ\n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:213] reference:der bau von bewässerungsanlagen erforderte den massenhaften einsatz von bäuerlichen arbeitern.\n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:214] predicted:o ist über wiedero beissenssenenangnhalleenlleititssenft wieemn erohercht sieüikgellelelik?\n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:213] reference:am schnabelansatz ist die haut bei vielen vögeln zur wachshaut modifiziert.\n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:214] predicted:mmer t wirtenmmeren sindikha  stirigen schonst beienz re tun fürleen zudglrei füro requgeb t\n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:213] reference:ich halte das für eine falsche alternative.\n",
      "[NeMo I 2022-05-31 14:56:20 wer_bpe:214] predicted:ichhen des sieive bolo stle dup.\n",
      "[NeMo I 2022-05-31 14:56:21 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:21 wer_bpe:213] reference:es gilt, maßnahmen zu setzen, die investitionen in den arbeitsmarkt fördern, z.\n",
      "[NeMo I 2022-05-31 14:56:21 wer_bpe:214] predicted:sie spalrastentengeblau sie desem desä überen b breigenlenfthen.\n",
      "[NeMo I 2022-05-31 14:56:21 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:21 wer_bpe:213] reference:habe ich sie gerade richtig verstanden?\n",
      "[NeMo I 2022-05-31 14:56:21 wer_bpe:214] predicted:a nur wichtigo diemm und.\n",
      "[NeMo I 2022-05-31 14:56:21 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:21 wer_bpe:213] reference:endlich kam die sultanin zum drittenmale nieder nicht mit einem prinzen sondern mit einer prinzessin die unschuldige hatte dasselbe schicksal wie die prinzen ihre brüder\n",
      "[NeMo I 2022-05-31 14:56:21 wer_bpe:214] predicted:erwder- zu wir nur freisftizischenten erf sch jy er nicht er nicht nur p pischen woanden desv deso freiandensscht wiederizizrä nuriz ich des zuranerbischenizteniz für p gs er ery für.\n",
      "[NeMo I 2022-05-31 14:56:21 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:21 wer_bpe:213] reference:im zentrum seines wirkens stand vor allem der ausbau der beziehungen zu den nachbarstaaten.\n",
      "[NeMo I 2022-05-31 14:56:21 wer_bpe:214] predicted:sch schgandensrtenlsigerwo se wieder michbischen.\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:213] reference:ohne einen waffenstillstand scheint es überhaupt nicht realistisch zu sein.\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:214] predicted:hen nicht der nachb überktill nurderal zuderä.\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:213] reference:jede form von verstaatlichung hätte es unmöglich gemacht, arbeitnehmerrechte hätte es beschränkt.\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:214] predicted:schw diesktv denionenauäück.\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:213] reference:um die grundbedürfnisse des lebens zu decken, braucht man dort jedoch mindestens ein hundert vier euro.\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:214] predicted:ich die auf mich zu den nur letz- ichtentenkt michder worder nichtvestst der.er,.der.\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:213] reference:in winterberg begann er die saison schon als zweitplatzierter.\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:214] predicted:a bei bachmegalsssch aufa wor.\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:213] reference:ich begrüße es ausdrücklich, dass die eu weiterhin einen maßgeblichen beitrag zur humanitären hilfe in der region leisten will er ist dringend notwendig.\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:214] predicted:dassenalthin wasberste je in es den p p das ihre zur ausge kt beinahmen,hals nichts wird,te als tin diet, nichtungige stest z.\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:213] reference:ich bin eben erst gekommen ils ont t charmants denken sie sich nur sie haben mir zu essen und zu trinken gegeben und das brot war geradezu wundervoll\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:214] predicted:haben bei etktrau derz deshalbrit alsung eahnberill nichtsr auchrit einen zuestst zulungier wurden aber nach nachinau ma tun ück b\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:213] reference:die wasserseite ist mit einer steinschüttung abgedeckt.\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:214] predicted:es es ob die es je for es viel esststörrstandkte zum\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:213] reference:der begriff wird von vertretern anderer politischer strömungen nicht selten abwertend gebraucht.\n",
      "[NeMo I 2022-05-31 14:56:22 wer_bpe:214] predicted:diete bezdertteauflleaush dut das mitrüinm diet seineäu der undill zur for die nachänlichische r wurdenöt mageben mitien in zur vier wstand ichdertsen inungsuntän,.\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:213] reference:jetzt kaufte er eines in der nähe der stadt mit großem zugehör von feldern wiesen und waldungen und da ihm das wohnhaus nicht schön und bequem genug schien\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:214] predicted:s sein je kststandriderteiun, ma in einhe mein strest sondern wö mari essch auchrüatz von auchungs und im in einelt ma for vertung es, esr haben zu rel stööö,achel.\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:213] reference:schließlich versucht violette, ihre eltern aus dem weg zu räumen.\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:214] predicted:fö denvstand in h die vorgebenshs..\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:213] reference:jörg zürn gilt als hauptmeister der frühbarocken plastik am bodensee.\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:214] predicted:pän alsmonaupt einensten der hömum damitel hösten.\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:213] reference:das bisherige mandat darf nicht auslaufen und muss noch diese woche verlängert werden.\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:214] predicted:jetztan un mirungen sein da gerade daatzauerfürfen unden im derlichensten diezen forternte f arbeit w jetzt h se ebenhalten.\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:213] reference:bei der bankenunion hat dieses parlament verantwortlich und schnell gearbeitet. vor zwei jahren bereits haben wir das gefordert.\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:214] predicted:wwerfenum dken verterncht se arbeitdfenna wtern wterngen fhmenein in dasrü eine f.\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:213] reference:leider hat der berichterstatter recht.\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:214] predicted:l jetzt h kam müssenmtern als fte.\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:213] reference:wir verlangen nämlich, dass dieses parlament das recht bekommt, selbst zu entscheiden, wo, wann und wie es tagt.\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:214] predicted:äand dass das diesesen derfck be dasss f.\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:213] reference:eine diplomatische z b meiner treu herr fix ich weiß nichts davon gestehe ich ihnen und im grunde gäb ich nicht eine halbe krone darum es zu wissen\n",
      "[NeMo I 2022-05-31 14:56:23 wer_bpe:214] predicted:llen der w der w willatzre deratan vert der wü wrin dort dass dasschthe dem d wanrinre gef dkenum warenumgrin den freiü w p waren undaus\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:213] reference:ich schüttelte alles ab und ging bestürzt nach hause meine cousine die aus hoffnungsloser liebe zu mir immer weinte und verse rezitierte kam mir entgegen\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:214] predicted:sch der alles von von und gebar dassf derf ver vor sein der wan eben derternften und ihre voräbenteein eben dassteeinrin zkendern der zu seineigeben.\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:213] reference:im bereich des straßentransports ist eine übereinkunft für alle nicht-mobilen arbeiter erzielt worden.\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:214] predicted:bcht htern wbei das allstenken dasforro t b am gee ausige sch verei bilis arbeit geannonil zu ge..\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:213] reference:den wir haben.\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:214] predicted:t werden und.\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:213] reference:all diese fakten werden von der berichterstatterin sehr klar und sehr ausgewogen aufgezeigt.\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:214] predicted:und es ver chat habendelich zein tkommensten begrianannun z vor zu b und und undbe\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:213] reference:er ist nach antwerpen centraal der zweitwichtigste bahnhof der stadt.\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:214] predicted:es tlichstenm ausrat leben sich sch zu..\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:213] reference:das fahrzeug sollte dann durch überarbeitung bessere werte beim crashtest bieten.\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:214] predicted:an entei ich halr wobei bbei nochemden hspatlichte gürdem.\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:213] reference:die entsprechende dienstbezeichnung für beamte im konsularischen dienst war vizekonsul.\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:214] predicted:gpl spür mireisenspffenkunant imge brau am grundonsen hlich alliraeissat verlatollerion diesesürbeibei g\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:213] reference:also was tun?\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:214] predicted:sehr jiplion.\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:213] reference:er nahm als österreich-ungarischer soldat am ersten weltkrieg teil.\n",
      "[NeMo I 2022-05-31 14:56:24 wer_bpe:214] predicted:b einer jedochbe allßchteß aus v vne da aus ve mir letz gstellt\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:213] reference:udo bullmann hat gesagt wir müssen jetzt nicht nur über szenarien reden, sondern handeln und sie umsetzen.\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:214] predicted:alles sehr g wie g imald istßeann gel wir wissendeno sehrne wieon arort ar nzen ent arannarönß.\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:213] reference:dort machte er seinen abschluss an der du pont manuel high school.\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:214] predicted:einesüpl er alles ab ab enterstann wiront mirschlz\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:213] reference:ich bin für das vermarktungsverbot. ich bin auch für das testverbot.\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:214] predicted:te i cter der ab wor ver mirannonortobaubaulichers v durch cg ctortodent\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:213] reference:sie wissen genau, dass sie inoffizielle koordinatoren meetings abgehalten haben, ohne einen teil der fraktionskoordinatoren eingeladen zu haben.\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:214] predicted:holichqug hatter ge de über mit wie ich wirieortacht eine diese fe polittz hatterend deteroerde über diese dieseer ar\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:213] reference:ich frage mich da auch immer wer ist denn „wir?\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:214] predicted:ausultult war,terarhin veter am schonieno werdende\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:213] reference:hier fungierte perez als managerin.\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:214] predicted:ich dem dem nichtgul diesesieges, isterstzmen beeichbarör parlament.\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:213] reference:die platten waren gelenkig miteinander verbunden.\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:214] predicted:ließ stadt warende nichtsk p ohne nicht pulst berichtielbent hat stra\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:213] reference:danach blieb es für lange zeit verlassen.\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:214] predicted:at eben wirichtigriie ohnezisch habenichtigugteungszente.\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:213] reference:daneben komponierte er werke für männerchor und lieder.\n",
      "[NeMo I 2022-05-31 14:56:25 wer_bpe:214] predicted:ulffs- ho kam hointela puau diese.\n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:213] reference:besonders da auf manche amtliche stelle leider kein besonderer verlaß ist und die versuche nicht ausbleiben werden die maßnahmen der obersten stellen zu durchkreuzen vielleicht hat die verhaftung einiger dieser bandenführer einigermaßen abschreckend gewirkt\n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:214] predicted:ichsteringten muss imeich genxol leitering ich ichierteichtigkk lie ausgez werdenin lietzam haben,zz stadtick zukk ichst ,agtatagt sch ü schs fürse wissenzzinzu schgens,hoch ohnearagt lie, manhmmtwot\n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:213] reference:das hat nichts mit den abstimmungen zu tun.\n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:214] predicted:daseinfferegen b sol.\n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:213] reference:er verließ seine mutter und seine sechs weiteren geschwister kurz nach seiner geburt.\n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:214] predicted:früster dassteeresterauf derstlah berot.\n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:213] reference:sein. die eu muss in ihrer handelspolitik alles daransetzen, dass menschenrechtsschutz konsequent umgesetzt wird. ein gutes beispiel waren die diskussionen über das fischereihandelsabkommen eu thailand und die sklavenähnlichen arbeitsverhältnisse in\n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:214] predicted:ko ko auf wissensb bischerlaster dan die mmsteeins hal wissenhn ihm liete lei ko alsdrsteu umtz daste erst dasla gen als hatste zuenten sie dort\n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:213] reference:europa fällt dabei eine wichtige aufgabe zu, einschließlich der finanziellen unterstützung.\n",
      "[NeMo I 2022-05-31 14:56:26 wer_bpe:214] predicted:ischer gebver ans der gerade er alsgen zu ich abgeungenen manenol st zu dan.\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:213] reference:zwei weitere türme sichern das haupttor.\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:214] predicted:es daend an einen mussse siesch alsung istau.\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:213] reference:frau kinnock, ich danke ihnen für ihre ausführungen.\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:214] predicted:alser dan dortck bei dan recht fürn versuungenb wer.\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:213] reference:der islam wird immer wieder unterschieden vom islamismus.\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:214] predicted:m erw da klar für konnster habenuachmar.\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:213] reference:dieser mechanismus ist eine wichtige grundlage, menschliche sprache verstehen zu können.\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:214] predicted:zwei isth na cung dan danten wer konla seinellchche aufcheungmarauptischer ver menschen müssenierteat..\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:213] reference:deswegen müssen wir im nächsten mehrjährigen finanzrahmen klare regelungen, finanzielle sanktionsmöglichkeiten finden.\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:214] predicted:ionen gu moränil wer binundenten ab reä reundenungchtunden ein eineord k hal er durch renungnungen fierte bei auf m gu nach fet er du besonders weiterla te haben b.\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:213] reference:somit ist die luft vollständig mit wasserdampf gesättigt.\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:214] predicted:d tunllen siezell über er abgese.\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:213] reference:\n",
      "[NeMo I 2022-05-31 14:56:27 wer_bpe:214] predicted:iger aufutz eu die siell tellenar um verslospgen. die s der da dieungtchtspielabche bin manuden die sdenten ver nach nicht diesem wereu ihre über immer darorbäntstänt dieeu ab konset müssenke ab gewunden eineniger dartungen ver manand.\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:213] reference:aber die flüchtlingskatastrophe, die wir verantworten, mitverantworten seit monaten, seit jahren die durch syrien verschärft wird, das ist eine schande!\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:214] predicted:ionenla auchcht ges ms hb eu ein klariger immer nichtsunchtabcht gew mitbeuontch auch entschhtko ein klartlarieitden seitv s\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:213] reference:es folgte ein dramatischer abstiegskampf.\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:214] predicted:ze sondernschschgtden.\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:213] reference:es wurde bei dem plattenlabel versus records unter vertrag genommen.\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:214] predicted:denhmen meckliet t.\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:213] reference:deswegen muss herr draghi ein ums andere mal eine kreative lösung gebären und mutig sein, um die eurozone zu retten.\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:214] predicted:ahr eine verbhmenige weiter\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:213] reference:deshalb brauchen wir hier strengere regeln.\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:214] predicted:waren teilderb\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:213] reference:heute vor neunzehn jahren wurde die russische verfassung angenommen, und genau heute hat der wieder präsident putin den moralverfall des landes beklagt, doch der verläuft von oben nach unten.\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:214] predicted:anges ver,raließmeutlakt\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:213] reference:im arbeitszeitrecht geht es aber im prinzip seit ein hundert fünfzig jahren um die frage des schutzes von menschen vor überlangen arbeitszeiten.\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:214] predicted:is istisat, steirkt,,isrinschliche,,, sch,, plander,,, jahren vie jahrenge derglichormpschschan,,s jahren.\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:213] reference:das reduktionsziel ist nicht ausreichend.\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:214] predicted:eine wird unter ihnen, hierragmpass aus abat\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:213] reference:auch mir bereitet die digitale kluft große sorge.\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:214] predicted:ra eineore istät seinen zweieiicht diegespienor kassmusmmen\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:213] reference:seit der mambo verlag zu sony music wechselte, führt curt cress das tonstudio weiter.\n",
      "[NeMo I 2022-05-31 14:56:28 wer_bpe:214] predicted:,ragorten gebver zwei eineführ llaurefton menschenussorskärsienut, diemusktiononischeriragführe.\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:213] reference:das transitive subjekt löst am verb keine kongruenz zum genus aus.\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:214] predicted:mus kinneichtsvereatl gelamho seinen kiischerführvereben durch.. so\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:213] reference:persönlichkeitsstörungen, kranke, perverse es ist eine katastrophe!\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:214] predicted:desließusft arbeitbeanftor herreip aber vondandelnerishmentw arbeit wirkeaternppver.\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:213] reference:gunther reinhardt vom \"\"rolling stone\"\" bezeichnete \"california über alles\" als „hardcore-version eines flamencos“.\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:214] predicted:in un denscam umllenhenam ami handelive aber dann ei des die istatatpusputz es das menschen amuss das.\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:213] reference:aus diesem grund ist die verbreitung sehr wichtig.\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:214] predicted:musoahnam desftige verl weiter befstimmmmen ic li fsch.\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:213] reference:von dort geht zunächst über die \"via po\" zum linken ufer des po.\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:214] predicted:o arbeitsatär n menschenidertch über das arbeitger dass zwiel undr we o ists hatsa das dasro.\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:213] reference:regeln sind am ende dafür da, eingehalten zu werden. das muss für kleine wie für große mitgliedstaaten gleichermaßen gelten. die stellungnahme des parlaments enthält aus meiner sicht klare botschaften.\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:214] predicted:wirc das ios dre die frast nach fraasangeni dericutentenäch geboj d wir d! esst dasst es ist aus verlllez istre seit einud r rfttw wiederst wirddert weiter des reigerer das t. esa arbeitangenmmen istsi einsperie der derord um menschenr gro aus teserivees nach.\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:213] reference:werden wir ihr einen fluchtweg einräumen?\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:214] predicted:frage könnendeiteni „s mal eine klstusstver heutessenssen\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:213] reference:zusammen soll dies das land mit den wäldern symbolisieren.\n",
      "[NeMo I 2022-05-31 14:56:29 wer_bpe:214] predicted:vert l rran p ges das lstcataegaver sp sung.\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:213] reference:schafft auch einsparungspotenziale in den mitgliedstaaten.\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:214] predicted:udreunutgeeihe diestz\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:213] reference:er ist auf dem uff-kirchhof in cannstatt begraben.\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:214] predicted:essk mussun folderanossen\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:213] reference:deswegen finde ich es gut, dass diese entscheidung jetzt endlich gefallen ist, mit dem wermutstropfen, dass großbritannien wieder einmal zum\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:214] predicted:hier gro sichbeni p hat seit gro gen seit finanz seitaupt das seiteit kl allesale\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:213] reference:der zweite punkt ist, dass wir sehen müssen, dass stabilität nicht das einzig entscheidende ist.\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:214] predicted:land grund jahrenzi besonder dasitg systar mit vonn\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:213] reference:von den achtzig tagen welche herrn fogg zur verwendung gegeben waren hatte er bereits allerdings zweiundfünfzig verwendet und es blieben ihm nur noch\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:214] predicted:zi regelwemauen grund genbne finanzalreich geht pzeit m syäl p mder geht im mzäligen\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:213] reference:er habe noch nie eine einzige note außerhalb irlands komponiert.\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:214] predicted:dort fl mo gen sy genal auch eingemauurpf?.\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:213] reference:es ist sache dieses europäischen parlaments, druck auf den rat zu machen und dringend eine effektive regulierung vorzunehmen\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:214] predicted:h mitßeal p parlament klnaroga den nicht austenanderr \"alieheru luheru pma.\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:213] reference:und zweitens was ist möglicherweise mit anderen herstellern?\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:214] predicted:fl ist ca doch in mit hatteh h der jetztäl.\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:213] reference:daraufhin beginnt das spiel mit der ersten sogenannten nacht.\n",
      "[NeMo I 2022-05-31 14:56:30 wer_bpe:214] predicted:ro heute fünf über am genen derru hatte seine er aus fünfauiert.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:213] reference:ich bin davon überzeugt, dass die im vorliegenden bericht enthaltene forderung nach einer stärkeren diversifizierung der gaskorridore eine klare verbesserung bringen würde.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:214] predicted:gen fl stgen son zum s dassm cigungen den beriglichhben fürau dasskommen und dass fin wro zum der wei aus parlamentdernro eur den p fürig regelhn dass zuspielro vers\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:213] reference:die maschine in tiefdeckerauslegung verfügte über ein starres fahrwerk und ein konventionelles leitwerk.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:214] predicted:im was enl ist b-f- zuigtau auch ist mussf und sch verboll st stroahe wurdeßenll beg?.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:213] reference:sie bietet jungen nachwuchstalenten die möglichkeit zum aufstieg.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:214] predicted:die wgigungfosv we? dielammlichist zu dass stjeg.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:213] reference:niemand kann uns diese arbeit abnehmen.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:214] predicted:olam meinhe keine meingenru dassgte\"ieren ist.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:213] reference:sie wird von der nordbahn eisenbahngesellschaft betrieben.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:214] predicted:eineshalten zum noch regtetierenn land landungenächag dassftagische entschtetum?.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:213] reference:die unterstützung, die die amerikaner und die europäer den deutschen vor dreißig jahren entgegengebracht haben, war ein echtes geschenk. dieser vertrauensvorschuss war nach zwei zerstörerischen weltkriegen alles andere als selbstverständlich.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:214] predicted:tet und die keine übereit einzig von und diegenleiol ge bereit verbach mein erstenfgen einz. istnhnst einzunggen meinhalten sttetilessizdede welgeneinechk  schgenälgeneinech.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:213] reference:für belarus, aber auch für die ukraine, übt das autokratische system russlands, das sich durch außenpolitische geschmeidigkeit und innenpolitische härte, unterdrückung und repression charakterisieren lässt, offenbar mehr anziehungskraft aus und gibt mehr orientierung als die angebote der eu.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:214] predicted:und mit ist nie nie von vorb wichtigkdegenßhaltenkeitess istv ister wel dieser ingen habeber istveneskent diehme dedededeekolitikbde b begfall nieungenktensetzk verbhalten dergenv von dm wel undenzerive esfor vor ist begde begenzllen.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:213] reference:der titel leitet sich entweder vom arabischen wort ab.\n",
      "[NeMo I 2022-05-31 14:56:31 wer_bpe:214] predicted:derckweutzkgenvmalv t vonreiive gutdenrach.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:213] reference:unsere fraktion fordert eine vollständige und gründliche untersuchung dieses sachverhalts.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:214] predicted:dieserte niekktdch nochunererfor vor dieses b entenditätinige mit untersterwermünk no n müssen diesemsachkü.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:213] reference:das bedeutet aber nicht mehr verkehrssicherheit, allenfalls einfachere polizeikontrollen.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:214] predicted:ärirerön unterstverk dieseer ends s nochriteck europäischenigungen.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:213] reference:sie werden seit sechs monaten immer wieder angekündigt, doch bisher hat sich nichts getan.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:214] predicted:niee derkeitünung herrierungmiertüiertüpar allen berichtesische.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:213] reference:gerade die hochspekulativen geschäfte mit staatsanleihen haben in der vergangenheit bewiesen, welche gefahren sie für unser finanzsystem darstellen.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:214] predicted:um der heutegteun demiveungischeständerischeraungdsßen herr mitgliedstaatenerder entsch dieseieige vom warenör mehrs mehr dem..t.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:213] reference:obwohl diese abschätzung nicht unmittelbar einleuchtend sein muss, ist der beweis sehr einfach.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:214] predicted:.tt ab \"ösungs,s einischensm ans unter mits mehrbt unter die dem einehes g mehrwer..\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:213] reference:dies ist uns anlass, auf bedeutende und grundlegende fortschritte in diesem bereich zu hoffen.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:214] predicted:unds waseisei ind nach undün entd gesch nachünständ führr nachde eingend ein.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:213] reference:im gleichen jahr wurde dieses system in betrieb genommen.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:214] predicted:imlandßch sein auch zweistemesetztss tsierungegeb t gp gehmandonschen.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:213] reference:zielgruppe waren professoren und studenten der universität, weniger interessierte laien.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:214] predicted:siepgeb wachtßen,rin verf gesch einrions amständ,stem gesch fürrallen ent.d eins ein\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:213] reference:bestimmungen in bilateralen verträgen zwischen der europäischen union und drittstaaten reichen aus.\n",
      "[NeMo I 2022-05-31 14:56:32 wer_bpe:214] predicted:aber wieder werden ent,ör ein sein ent zusammenung die der,zschenonieren edschen, aber.\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:213] reference:viele details des wohnbaus sind von interesse: an den fenstergewänden sind steinmetzzeichen zu finden.\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:214] predicted:westell daswo zweiün ein und weltrrinragend, einusssel geie konraern in gef eins zei,ieschen sind\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:213] reference:dazu gehörte auch eine steigende inflationsrate und eine zunehmende kriegsmüdigkeit.\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:214] predicted:zu sieul möglich möglich,t nachb ein einge kein der wten d aufte in re undionzz unstemaatllen beb abigt\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:213] reference:ich habe häufig vernommen, für die forschung seien mehr ressourcen nötig.\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:214] predicted:ul zwei sich anru andere, dievoruss anungenä bearungs an“ anrie.\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:213] reference:mit blick auf das, was wir in den letzten jahren schon in sachen cybersicherheit in europa vor allem auch mit hilfe des europäischen parlaments auf die reihe gebracht haben, glaube ich, dass wir ganz gut ausgerüstet sind.\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:214] predicted:sich das dasenalenaat anei redrunktwofachfachfachllenten vorrie verl ver vomen anbss in zurfall,ieeibarfach der zweissver syütz grundverver\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:213] reference:möchte jemand gegen diesen antrag sprechen?\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:214] predicted:uns fschen\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:213] reference:wie hoch ist die zahl der verletzten unter der zivilbevölkerung?\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:214] predicted:y,weise der ver dreienin in unsory\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:213] reference:dies ist angeblich auf fred astaire zurückzuführen, der auf diese perspektive bestand.\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:214] predicted:den darauf in zieltegtmito bedeä dies.\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:213] reference:auch die geplante zusammenarbeit bei gesetzen, normen und standards riskiert eher, die bei umwelt, tierschutz, verbraucherschutz, arbeitsrecht und sicherheit am arbeitsplatz besseren europäischen standards zu schwächen.\n",
      "[NeMo I 2022-05-31 14:56:33 wer_bpe:214] predicted:die dieere pütte sindsen auchyeinüücktetenstaaten grstaatenchenchen nich ses dieütz ihm dies diesge klar in dieden bechen leichenfsstenüfichuchwuch nichtück aufstaatentente inchen inchen indertt am arbeitchen,rie auf indert obs beess vorden behlheit europäischen bis, sesschchen,\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:213] reference:mit ihrer arbeit können bürgerstiftungen gestaltend eingreifen und als promotoren sozialen wandels agieren.\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:214] predicted:fg undlandausst berä in unstauserstückriete in grdendengt z ch hchensigegeielz.tenden.\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:213] reference:ich stehe hier, um mich für diese arbeitsintensiven dienstleistungen einzusetzen.\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:214] predicted:eine fürschiztogchen sindenys vom auchor unserch unserent\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:213] reference:weil manche unternehmen nicht genug verdienen können oder verbraucher nur noch billig wollen oder sich nur noch billig leisten können.\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:214] predicted:diest be jche s forste, derherg die auf auf versp ver dägaus alleswo wieder auf der sindenchetenen aufheitgfspheit auf rei kkentenheit\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:213] reference:wer hätte solches bei diesem ehemaligen internationalistischen marxisten jemals für möglich gehalten?\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:214] predicted:die dielich veren herand b d henheit k aheit spscht zu nichtiv sthinessg se fing ichleien.\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:213] reference:er sprach darüber ob denn keine möglichkeit sei ob es sich nicht machen ließe darja alexandrowna stockte deine lage zu ändern zu verbessern du weißt wie ich darüber denke\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:214] predicted:ä ate hheit ichppen einen aen drau hen hleirechen geb ge syen europäischenleirechenrechenu h als zu auf arbeit sehr cheistimmlei als un hlei angeeng\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:213] reference:zusätzlich wurde jedoch der fahrplan am abend ausgeweitet.\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:214] predicted:eis ich dies ich warot einen jierungalenetierung aus außer bet gew lei\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:213] reference:benimm dich anständig!, mahnte christiane an.\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:214] predicted:ammmenischem ichst bisd warsp, n..\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:213] reference:außerdem ist der einsatz von samples etwa aleister crowley zu hören ist.\n",
      "[NeMo I 2022-05-31 14:56:34 wer_bpe:214] predicted:wie aus außernennehmenem dieses wiebar bet unter stabstesesheitsetz nicht\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:213] reference:meine sorge ist, dass wir jetzt zu verwässerungseffekten und substitutionseffekten kommen zwischen finanzprodukten und versicherungsprodukten.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:214] predicted:ft glau glauaochser verb nur. glau proi machen ge sei prostkt nur dazuungfe könnenandalen durch finsi unter e r unionsta europa.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:213] reference:entsprechend muss die eu, müssen die eu mitgliedstaaten ihre verantwortung übernehmen, müssen ihren teil leisten, um den frieden im nahen osten sicherzustellen.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:214] predicted:lir durch biloch nurir für diesem ge des eoch undiesbe immerierans b beibarand und glau eben fgergeroch ste steen, zuatzabeembeivmmen\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:213] reference:seine werke sind im besitz öffentlicher und privater sammlungen.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:214] predicted:wie dar weralen wir beike mit mitstfenischen und nichtrithmen undien.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:213] reference:es geht darum, die bearbeitungseffizienz zu erhöhen.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:214] predicted:a dar stwei erar zu könnend den\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:213] reference:die begegnungen wurden unter den verlierern der viertelfinalspiele ausgespielt.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:214] predicted:bei ihrer letzd bungien und zwischenarnehmenteick sarchrau pro ihrerikination ganzraud wir wir obbeitrau inter zu wirig\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:213] reference:und die freundschaftlichen gespräche wollen wir auch fortsetzen.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:214] predicted:ater unter verbanhenungk an alreiungen,ationbeitollrausetz.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:213] reference:das hilft im übrigen dann auch, um die europäischen schulden, die wir jetzt aufnehmen, wirklich zu bedienen.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:214] predicted:stenl desständffe lei istritbenemmmenffe undien europäzivd letzw nichtnehmenem möglich. den.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:213] reference:dies umfasste nicht nur die nutzlasten des space shuttle, sondern auch von delta-raketen.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:214] predicted:ist um was ist um st maigkeit gut finanz inter wasnehmense istse a interweisten auch fürv wurdezu den f\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:213] reference:lebensmittelproduktion hat sehr viel mit den regionen vor ort zu tun, mit den menschen, die darin arbeiten, und das hat auch damit zu tun, wie wir dann mit der umwelt umgehen.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:214] predicted:lehät wollenrei fnehmen wirsridu zuro nicht fkeseachen verwhmen den beisten umk un zul besandelhn f arbeitsten sdu, denn b meine interri wollenhenklichsten wollen figker um den\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:213] reference:es handelt sich vor allem in holz errichtete streifenhäuser.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:214] predicted:setzdu ma seineierlehen stortleierdulew finanzknehmenareltieren.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:213] reference:mira möller arbeitet als sachbearbeiterin bei der bundesagentur für arbeit in schwerte.\n",
      "[NeMo I 2022-05-31 14:56:35 wer_bpe:214] predicted:nehmenri alhem darort iststen, s, arbeitker bei der p orau p verb arbeiteu stan,\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:213] reference:sein grab befindet sich auf dem johannisfriedhof in tolkewitz.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:214] predicted:seineastenahr michke d können der können gegen.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:213] reference:der drache speit feuer.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:214] predicted:jetzttelle stplwei teil...\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:213] reference:sie zog sich in ein kleines nebenzimmer zurück und ließ sich an dessen fernstem ende auf einen sessel sinken der luftige rock ihres ballkleides bauschte sich wie eine wolke um ihre schlanke gestalt\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:214] predicted:muss imktiontz, lamenal im ßemmern erft im  sich auch is, dassan dieten d dafüra der sohostentin. dieutz auch ftu euund  sich der aucher wo swir   eu die weiro  die ihrener  dke jahrense\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:213] reference:ruby keene drohte nun alles zum scheitern zu bringen.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:214] predicted:auch beur dieier sichro derstezuschaftrie sschaft ausgeten sp den..\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:213] reference:innerhalb eines blocks kann es ja gute und schlechte vorschläge geben.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:214] predicted:noch inerinort,ungen schoner auchke dar eu.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:213] reference:die evp will die tagesordnung ändern, weil sie im ausschuss keine mehrheit für einen änderungsantrag bekommen hat.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:214] predicted:all auchol die star ste d zu gest und wurdenße,inbei es dar ausgeließ zurag bürger sehrtel sper,.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:213] reference:nichtsdestotrotz ist dieser zweite mehrjahresplan nach dem ostseemanagementplan ein sehr wichtiger schritt zur richtigen zeit.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:214] predicted:ilck zutel ratur weil vor die deresh sicher,eerplern sondernrachin sondern s sichfdetrieöänplan dinhislich die gehtte spgebftc sich zulich b sichal\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:213] reference:im ostseeplan sehe ich eine blaupause für die weiteren mehrjahrespläne, das heißt unter anderem auch für diesen nordseeplan.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:214] predicted:umesfcherante,inmit darck die überke ihrein jetzta. deses vorin sich der umees diej bcheran.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:213] reference:es ist zwar kein medikament, aber offensichtlich trägt dieses fieberthermometer dazu bei, dass die patienten in eine noch wesentlich schlimmere lage kommen.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:214] predicted:all allän arbeitw handel sichdemßesutenaweroterax heichessbeu sch sich umher.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:213] reference:nach dieser und weiteren akten des kongresses wurden weitere bibliotheken errichtet.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:214] predicted:ten ne sch b undahrtenseseraglaasro undru odero sp sichalgehtet.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:213] reference:fünf tage bevor die tour startete musste ich ihn nach hause schicken.\n",
      "[NeMo I 2022-05-31 14:56:36 wer_bpe:214] predicted:sondern umderwkee fred alrachorttet undol danne sch deutschharieten um dem..\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:213] reference:dieses dossier ist fix und fertig verhandelt, es liegt auf dem tisch.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:214] predicted:schund dieb mehrjätz um jahrf mitänann. mit mit damit l aufund finsch...\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:213] reference:ursprünglich standen kirche und kloster auf einer kleinen erhöhung außerhalb der stadtmauern.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:214] predicted:h ösp be dannen er schal etwa auf bauzuan er in erolrungen ar er sch sch inakordeesen.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:213] reference:das parlament hat durch den vertrag von lissabon neue zuständigkeitsbereiche erhalten.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:214] predicted:jj m kobpl diesentsch da ist zur mitt zur be ihrahrtpeigen ihre müssenjes erhalbernulord zstem in ihr zurücklaenspeserelt.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:213] reference:zudem haben einige auch anlaufstellen speziell für menschenrechtsverteidiger geschaffen.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:214] predicted:b imarpän regp o handel für vorengeß von haträ zur hat aufpfen\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:213] reference:aber wir haben noch keinen nobelpreis verdient für den sozialen frieden im inneren, den müssen wir uns erst verdienen.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:214] predicted:ber ta dieser ander von kannespräen hat aufes zahligenrieß mehr tge nur sie sie müssenfl mehrste aufplanede.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:213] reference:es ist ja schön, und ich beglückwünsche sie, herr kommissar, dass wir vor kurzem einen arktischen dialog zu energiefragen mit island eröffnet haben.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:214] predicted:sein esussp zeit tuggem sol ein ko t esahrse es koutulung amord o vert wichtigierte wengeomche tspent sehr er für.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:213] reference:hat das auch seine richtigkeit?\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:214] predicted:sein vieleot dass auf eineräneit denn.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:213] reference:dieser wehrturm diente dem schutz vor überfällen an der alten heerstraße nach gardelegen.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:214] predicted:des diese eineitmenskehrd enstemutzs eineslesenutot wfcht vertas es nachteteplen.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:213] reference:wir kommen nun zu den anfragen an herrn kommissar monti.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:214] predicted:im kannern für t t fes ta inent erner sa sozii\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:213] reference:tamilen sind ethnisch, sprachlich und kulturell mit den anderen dravidischen völkern südindiens verwandt.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:214] predicted:tche keincheste mitkdffenfdern dasdllent en w therten inchetetsllt.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:213] reference:ich bin sehr froh, dass viele hier im haus auch für eine quotenregelung eintreten.\n",
      "[NeMo I 2022-05-31 14:56:37 wer_bpe:214] predicted:stekeni w dheremeusseusierte ich einen t eineoken undangen wichtigweren.\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:213] reference:frau präsidentin, herr kommissar!\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:214] predicted:habenem parlamentientiss haben\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:213] reference:einige augenblicke nachher schlug die prinzessin die augen auf wandte den kopf nach beiden seiten sah die umstehenden an setzte sich dann auf\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:214] predicted:a argeingik gefstehs f jall l np p berf f kli tun r weiterffentdehalbisso ist für dieseno ja wirzemhe!äizmmen r ta esfditztern\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:213] reference:ein staat, der versucht, vor dem täter und vor der tat am tatort zu sein, wird schlussendlich seine legitimation verlieren und scheitern.\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:214] predicted:haben dasste bien, haben fürandenlau, klhalb willbanden für nuss nach ged selbstherftien wir fürs fürner undeimiss zum\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:213] reference:das unternehmen war insgesamt erfolglos.\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:214] predicted:dasosenr überd habenien ihnar.\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:213] reference:kamele können nicht gehalten werden, weil geeignete weiden fehlen.\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:214] predicted:verar könnenölaukeitenern weiterlau nacht weiter einige neich vor.\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:213] reference:es gibt einige eckpunkte, die wir berücksichtigen müssen.\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:214] predicted:zwei kein einen anichen anhelaukeit den leiterog willm hathn,.\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:213] reference:ich will aber nicht, dass algorithmen darüber entscheiden, was online zu sehen ist und was nicht.\n",
      "[NeMo I 2022-05-31 14:56:38 wer_bpe:214] predicted:, aber habenit,it das dassu vers g vershey dem gtzit anktiontzö diick dem ver\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:213] reference:bei den chartplatzierungen konnten sie allerdings nicht an blue system anknüpfen.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:214] predicted:an iischenzrgen, dieserllgen machenlo nun dem und.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:213] reference:während der letzten plenarsitzung in brüssel musste uns ein kollege schmerzlich daran erinnern, dass selbst im europäischen parlament mittelalterliche und äußerst bedenkliche äußerungen gegenüber frauen gemacht werden.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:214] predicted:abertz weil wönhner nach an imururonreter an einige nachi nachei nach einigeessur im mre menschen, mir einige anigkeit,, dass einige k i einige,,usterit kur nach ibei.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:213] reference:die hauptstadt des departamento sarmiento ist villa media agua.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:214] predicted:die außerritt stadtit spat ein schlro einigemro menschenigerro tun.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:213] reference:deshalb ist das in diesem fall sehr schwer gegenüber den wählerinnen und wählern zu rechtfertigen.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:214] predicted:el dass sieloats den dieserhenfel ein sie eine den ichben ichrev werdensicht,re dergen.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:213] reference:so ein herrisches frauenzimmer ist mir noch nicht untergekommen!\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:214] predicted:zweigeieixerstammon schlel demhl.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:213] reference:wir müssen uns eingestehen wir sind gescheitert.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:214] predicted:ichmü allessstenraständelichdengtektgieter den\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:213] reference:in peruanischen schachturnieren fungiert sie als schiedsrichterin.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:214] predicted:im werden den e seineundu kommissralich wirelnung und werdenischäugr schsber vor wird aber.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:213] reference:dieses wichtige thema muss in erster linie auf nationaler ebene behandelt werden.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:214] predicted:dieser sch kourdenmmerischung uns seinester auf w seine kommissü aberarurdenung\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:213] reference:rauchen ist zweifellos gefährlich für die menschliche gesundheit.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:214] predicted:frauu istall zwübers ge dentelichgr dieden undliche sch willlicheark und!\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:213] reference:ich danke ihnen, dass sich mich zum abschluss kommen lassen.\n",
      "[NeMo I 2022-05-31 14:56:39 wer_bpe:214] predicted:deshalb ich sindhen s der sind vieligen war kon zumtst ab schse ko fraukommengress.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:213] reference:wir müssen finanzielle hilfe sehr schnell leisten.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:214] predicted:unter noche plte fandel ein frauachtille\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:213] reference:durch den zusatz herbal wurde unmissverständlich auf einen pflanzlichen ursprung hingewiesen.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:214] predicted:sieicht unter ein schu satzgachttera zu dent lg vnungen gegentt\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:213] reference:die unterkunftsmöglichkeiten dort sind auf wenige kleine ashrams und gasthäuser beschränkt.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:214] predicted:diegatacht müssenmmercht vst sind dazugkei derepl liche selbst istand v sch gibt.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:213] reference:die regierung milošević sagte den rückzug der nicht-bosnisch-herzegowinischen kämpfer zu, einer eher unbedeutenden zahl.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:214] predicted:ist in chüberüberhieachtst sehrg sehr zuurandüberten w kommissar\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:213] reference:unsere starke europäische wertegemeinschaft ist nicht unverwundbar, das mussten wir leider letzte woche in wien durch diesen terroranschlag erkennen.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:214] predicted:ist nochacht kung herr europäischen gesch werden t kisch müssen ich ist nicht nichtbl gem be dieses kur müssenatzster frau ist diesessicht sindatzaunschle erk.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:213] reference:und jetzt werden sie bedroht von einem türkischen einmarsch, von erdoğan, der vorhat, die grenze zu überschreiten und dort hineinzugehen.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:214] predicted:jetzt bei diesesllandel europäischenlicheacht diesesh h k zuschlten und  bl. nicht zu unterdüberg\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:213] reference:zahlreiche industrie und finanzunternehmen sind unmittelbar von emir betroffen.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:214] predicted:bei lalich wir iststerischenernung unter mern w mö müssenge müssen uns.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:213] reference:ich will nicht wiederholen, welche erklärungen und positionen ich und die anderen kolleginnen und kollegen im haushaltskontrollausschuss in diesem zusammenhang schon vom rat gehört haben.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:214] predicted:ist gegen zu beie zualung nicht herr p zu zuation gem nicht istlichenählult in hser kolo in inten ist zuischen nicht nicht ein der haus.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:213] reference:seine brüder waren nicolás und der general und diktator francisco franco.\n",
      "[NeMo I 2022-05-31 14:56:40 wer_bpe:214] predicted:fe eineück be aller auch nicht nicht lalinh men gegen nicht deteräterpfern zu nicht kleinfen gestlichener?.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:213] reference:über einem heer von kollektiven geistwesen standen gottähnliche „gestalten“.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:214] predicted:auf vor auch heraferischilgeischenragen unischeril sehr mir des me recht gef präsident rechtfer ihnenhileitenkb er letzierier dieück nicht tmmen.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:213] reference:die gleise sind teilweise noch vorhanden.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:214] predicted:dieige in teild verhlegen ernungugo unb-ähr anderenne.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:213] reference:wir sind deshalb enttäuscht, dass der berichterstatter alles versucht hat und weiterhin versucht, dass diese beiden aspekte nicht im bericht bleiben.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:214] predicted:se wir in derusheitfer kollellor men undg.g. der alsieren be plichlichreisch ferurk t age und w verl der versuss leilsvus entsch einerischens gef w derkt die nicht inllor und kolle undglichnetenb.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:213] reference:gleichzeitig rief sie die anderen frauen von stand auf, sich ihr anzuschließen.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:214] predicted:, r recht wirgeze dieh dienehmenanh parlamentllenieren seer dazucv parlament..\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:213] reference:mitteilungen aus dem institut für volkskunde hamburg\"\".\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:214] predicted:usäuohteinnglichkt durch f dersos kono gehör.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:213] reference:in diesem haus sind wir alle zur sicherheit unserer mitbürgerinnen und mitbürger verpflichtet.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:214] predicted:werden hausurcünblrüorougück ges letz..\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:213] reference:sie ist die einzige schülerin des karikaturisten und comiczeichners gerhard seyfried.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:214] predicted:wer dann erfolan leiständat weiterskte konhem lei zweist a forenen.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:213] reference:aber ich betone noch mal das kann nur der anfang sein, denn am ende müssen wir wirklich zu dem zwanzig milligramm grenzwert kommen und dürfen jetzt nicht bei sechzig stehenbleiben.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:214] predicted:und unsere,en hei wurderan. e mussierschm unückoscverziigearenc uninnenungenfeartccht durchschziamein,.\n",
      "[NeMo I 2022-05-31 14:56:41 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:213] reference:wir haben in der letzten plenarsitzung zum thema antibiotikaresistenz eine entschließung angenommen.\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:214] predicted:letz sieionen fünfu,zucht,at finanz und finanzo und finanzalo undiärins un einem reg „ anderen\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:213] reference:wenn wir morgen die beiden berichte annehmen, dann werden wir unangemeldete vor—ort—kontrollen einführen.\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:214] predicted:am waren,itz finanzunde b, diesem. walinnen von, b und men einemroskroäu finanzt,sch undön undund finanz\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:213] reference:wichtig ist, dass die debatte um nationale einschränkungen nicht auf dem rücken der bauern geführt wird.\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:214] predicted:dass diebat „ mragungenoscha mi vonro von vonragen k densch mitat.\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:213] reference:in österreich bezeichnen sich manche orte nur aus werblichen gründen als \"weinort\".\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:214] predicted:ichteriv weriznehmen dass m ganglichereiteros dar berichtche n diesemstein michitan.\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:213] reference:es ist nicht tolerierbar und gehört bestraft.\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:214] predicted:zahlbon undigedürzscha.\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:213] reference:und hatte alexei alexandrowitsch gegenüber auf die unschicklichkeit von annas engem verkehr mit betsy und wronski andeutend hingewiesen alexei alexandrowitsch hatte sie in scharfem tone unterbrochen\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:214] predicted:und hat statauptherzuamangterte b mgending über die unonsteigdschwig\"tding\"hn mit beidssenit bürinsk\"kttenauptäionang alterteattepftürbkommenkommen\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:213] reference:eine traurige bilanz in dieser frage.\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:214] predicted:wirherher b wirwianzon aufeitente\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:213] reference:hier war sie zuletzt als schriftführerin mitglied des präsidiums.\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:214] predicted:b gleichosd gstte dertewtol mitüsch plconzm mitben.\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:213] reference:ach ich bete das meer an stimmte leo bei haben sie nicht auch die empfindung fuhr frau bovary fort daß die seele beim anblicke dieser unermeßlichen weite flügel bekommt\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:214] predicted:in ich aus mal wer se dassanzgem ananzigdgemwer dglichwie bei diesem an am dann diesem ein wir nicht hinanzhnwungs wirrsteede demzienungenotro aufr vond das dass sebenin did unschrtelichen beiürbb übercom\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:213] reference:es ist mancherorts vergessen worden, dass auch sie zu den verschlungenen aller rassismen gehören.\n",
      "[NeMo I 2022-05-31 14:56:42 wer_bpe:214] predicted:deshalb es unenttelte dort\" aus ver g ausbenikb dasditinitz enlieikbenotschungenben ein esgemotinnenungenungenenbenllen.\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:213] reference:dabei ist doch gerade diese frage zur diskussion gestellt was hilft wirklich gegen den terror?\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:214] predicted:ich deshalb al er ein dies hinuwerikwier alx sie dasosonos ausrantee aufsch dieilichen in enentert or al\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:213] reference:vom selben architekten entworfen wurde der u-bahnhof \"baixa-chiado\".\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:214] predicted:xiewieonü einzinr dortort demol würde denühem kamamft beihemhem\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:213] reference:frau de palacio ist stets in hervorragender weise für die europäischen interessen eingetreten.\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:214] predicted:an bauussiehaltolde wei ver gehörnenleifen sindließen.\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:213] reference:der spontane informationsaustausch hat seit acht und dreißig jahren nicht funktioniert und die eu kommission hat gepennt, bis zu luxleaks.\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:214] predicted:anran ausort werdenft jetzt sie wei richtnenrinmmek siexomurgk.\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:213] reference:tamba grenzte an die provinzen harima, ōmi, settsu, tajima, tango, wakasa und yamashiro.\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:214] predicted:bar\"wer gehör nationeronen kollezeich wirdhem wenroubar tgee\"e bei-ierungale hier ich,sensenft\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:213] reference:fordert die europäische union die schließung des gefangenenlagers guantánamo bay.\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:214] predicted:dort \" bet nurionenten \" nicht hin habenmmenfsenderderelysen wird denit gr an eine\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:213] reference:hoffentlich gelingt es uns auch künftig, sie zu erhalten.\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:214] predicted:h aufpfleiaer aufk tir bet nichtisar. icheraa\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:213] reference:er starb in der geiselhaft in beirut nach krankheit und misshandlung.\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:214] predicted:ory tbe t fare,anden in hy in-ortaryshraarungummmena bet,aaa\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:213] reference:böse zungen behaupten, sie wollte den graf in einen handfesten skandal verwickeln.\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:214] predicted:, ay sie zorangeahnendengel bei hwi wor f dieo \"chys in anch dieor in an alsftchustenfk dennürfy ver wirklichiuffen c warp war.\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:213] reference:er wußte daß es nicht sehr schwer war diesen jungen zum plaudern zu bringen und entschloß sich sein bisheriges incognito aufzugeben aber es war keine zeit zu verlieren\n",
      "[NeMo I 2022-05-31 14:56:43 wer_bpe:214] predicted:derft des hatte wasßu die des dennscha als einge anumar vomßplrü an fragebistenso un sch manschlchis seenden fragee betftßte emas eingey noch emhensk. aš s desstßsar ceiy bez hattefitigstseno.o\n",
      "[NeMo I 2022-05-31 14:56:44 wer_bpe:212] \n",
      "    \n",
      "[NeMo I 2022-05-31 14:56:44 wer_bpe:213] reference:einer seiner enkel war der maler karl keller.\n",
      "[NeMo I 2022-05-31 14:56:44 wer_bpe:214] predicted:in wirklich einge seinezeei den sindill insenzderio port.\n"
     ]
    }
   ],
   "source": [
    "# And now we can create a PyTorch Lightning trainer and call `fit` again.\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer(devices=1, accelerator='gpu', max_epochs=20, log_every_n_steps = 100000)\n",
    "trainer.fit(asr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a33WIRR9B_gR"
   },
   "source": [
    "So we get fast convergence even though the decoder vocabulary is double the size and we freeze the encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alykABQ3CNpf"
   },
   "source": [
    "### Fast Training\n",
    "\n",
    "Last but not least, we could simply speed up training our model! If you have the resources, you can speed up training by splitting the workload across multiple GPUs. Otherwise (or in addition), there's always mixed precision training, which allows you to increase your batch size.\n",
    "\n",
    "You can use [PyTorch Lightning's Trainer object](https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html?highlight=Trainer) to handle mixed-precision and distributed training for you. Below are some examples of flags you would pass to the `Trainer` to use these features:\n",
    "\n",
    "```python\n",
    "# Mixed precision:\n",
    "trainer = pl.Trainer(amp_level='O1', precision=16)\n",
    "\n",
    "# Trainer with a distributed backend:\n",
    "trainer = pl.Trainer(devices=2, num_nodes=2, accelerator='gpu', strategy='dp')\n",
    "\n",
    "# Of course, you can combine these flags as well.\n",
    "```\n",
    "\n",
    "Finally, have a look at [example scripts in NeMo repository](https://github.com/NVIDIA/NeMo/blob/stable/examples/asr/asr_ctc/speech_to_text_ctc_bpe.py) which can handle mixed precision and distributed training using command-line arguments."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ASR_with_Subword_Tokenization.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
