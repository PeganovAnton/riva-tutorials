{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "719050b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e11db7",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# The Making of RIVA German ASR Service\n",
    "\n",
    "This notebook walks you through the step-by-step process that NVIDIA engineers employ to develop the Riva German ASR service, from raw transcribed audio data to a ready-to-serve Riva ASR service.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The below diagram provides a high-level overview of the end-to-end engineering pipeline required to realize the Riva German ASR service.\n",
    "\n",
    "<img src=\"./german-workflow.PNG\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417f79c-27d9-40b6-8929-eca53f73245c",
   "metadata": {},
   "source": [
    "The whole workflow is divided into 4 major stages:\n",
    "- Data collection\n",
    "- Data preparation\n",
    "- Train and validation\n",
    "- Riva deployment\n",
    "\n",
    "In the next sections, we look deeper into each of these stages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a237f9-2dbb-45b8-b8d9-2bca53101c4d",
   "metadata": {},
   "source": [
    "## 1. Data collection\n",
    "When adapting Riva to a whole new language, a large amount of high-quality transcribed audio data is critical for training high-quality acoustic models. \n",
    "\n",
    "For German, there are several sources of public datasets that we can readily leverage:\n",
    "\n",
    "- [Mozila Common Voice](https://commonvoice.mozilla.org/en/datasets) (MCV) corpus 7.0: 571 hours \n",
    "- [Multilingual LibriSpeech](http://www.openslr.org/94/) (MLS): 1918 hours\n",
    "- [Voxpopuli](https://ai.facebook.com/blog/voxpopuli-the-largest-open-multilingual-speech-corpus-for-ai-translation-and-more/): 214 hours\n",
    "\n",
    "The total amount of public datasets is thus ~2700 hours of transcribed German speech. In addition, to train Riva world-class models, we acquired many more hours of proprietary datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4eb6c-97c7-454f-87cf-f5bc97328c96",
   "metadata": {},
   "source": [
    "## 2. Data preparation\n",
    "\n",
    "The data preparation phase carries out preparation steps required to convert the diverse raw audio datasets into a format that can be efficiently digested by NVIDIA NeMo toolkit. These steps are:\n",
    "\n",
    "### 2.1. Data normalization\n",
    "\n",
    "Audio data acquired from various sources are inherently heterogenous (file format, sample rate, number of audio channels). Therefore, as a preprocessing step, we convert these audio data to a common format. \n",
    "\n",
    "Text Normalization converts text from written form into its verbalized form. It is used as a preprocessing step for preprocessing Automatic Speech Recognition (ASR) training transcripts. For German text normalization, we primarily leverage NeMo text normalization [library](https://github.com/NVIDIA/NeMo/tree/main/nemo_text_processing/text_normalization/de). In addition, we also Also tried to convert all outdated German word spellings to modern spelling.\n",
    "\n",
    "Dataset ingestion scripts are used to convert the various datasets into the standard manifest format expected by NeMo.\n",
    "\n",
    "### 2.2. Data cleaning/filtering\n",
    "\n",
    "This step is carried out to filter out some outlying samples in the datasets. \n",
    "\n",
    "- Samples that are too long, too short or empty are filtered out.\n",
    "\n",
    "- In addition, we also filter out samples that are considered 'noisy', that is, samples having very high WER/CER w.r.t. a previously trained German models. \n",
    "\n",
    "\n",
    "### 2.3. Binning\n",
    "\n",
    "For training ASR models, audios with different lengths may be grouped into a batch. It would make it necessary to use paddings to make all the same length. These extra paddings is a significant source of computation waste. Splitting the training samples into buckets with different lengths and sampling from the same bucket for each batch would increase the computation efficicncy. It may result into training speeedup of more than 2X. \n",
    "\n",
    "We leverage NeMo conversion [script](https://github.com/NVIDIA/NeMo/blob/v1.0.2/scripts/speech_recognition/convert_to_tarred_audio_dataset.py) to carry out this step.\n",
    "\n",
    "### 2.4. Train and Test splitting\n",
    "\n",
    "This step is a staple of the any deep learning and machine learning development pipeline, to ensure that the model is learning to generalize without overfitting the training data.\n",
    "\n",
    "### 2.5. Tarring\n",
    "\n",
    "If experiments are run on a cluster with datasets stored on a distributed file system, the user will likely want to avoid constantly reading multiple small files and would prefer tarring their audio files. You can easily convert your existing NeMo-compatible ASR datasets using the conversion [script](https://github.com/NVIDIA/NeMo/blob/v1.0.2/scripts/speech_recognition/convert_to_tarred_audio_dataset.py).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b800ff3-a9ff-49e8-aa15-e305f377f244",
   "metadata": {},
   "source": [
    "## 3. Training and validation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8cf5e4-49f8-49e7-a763-ab8fb58bfab1",
   "metadata": {},
   "source": [
    "## 4. Riva deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35767c7-174a-442f-9a21-c2769d870b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
